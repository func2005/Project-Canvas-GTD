{
  "version": 3,
  "sources": ["../../../../../node_modules/rxdb/src/plugin.ts", "../../../../../node_modules/rxdb/src/replication-protocol/checkpoint.ts", "../../../../../node_modules/rxdb/src/replication-protocol/helper.ts", "../../../../../node_modules/rxdb/src/replication-protocol/meta-instance.ts", "../../../../../node_modules/rxdb/src/replication-protocol/downstream.ts", "../../../../../node_modules/rxdb/src/replication-protocol/conflicts.ts", "../../../../../node_modules/rxdb/src/plugins/attachments/attachments-utils.ts", "../../../../../node_modules/rxdb/src/plugins/attachments/index.ts", "../../../../../node_modules/rxdb/src/replication-protocol/upstream.ts", "../../../../../node_modules/rxdb/src/replication-protocol/index.ts", "../../../../../node_modules/rxdb/src/custom-index.ts"],
  "sourcesContent": ["/**\n * this handles how plugins are added to rxdb\n * basically it changes the internal prototypes\n * by passing them to the plugins-functions\n */\nimport {\n    RxSchema\n} from './rx-schema.ts';\nimport {\n    basePrototype as RxDocumentPrototype\n} from './rx-document.ts';\nimport {\n    RxQueryBase\n} from './rx-query.ts';\nimport {\n    RxCollectionBase\n} from './rx-collection.ts';\nimport {\n    RxDatabaseBase\n} from './rx-database.ts';\nimport type {\n    RxPlugin\n} from './types/index.d.ts';\n\nimport { overwritable } from './overwritable.ts';\nimport {\n    HOOKS,\n    runPluginHooks\n} from './hooks.ts';\nimport { newRxError, newRxTypeError } from './rx-error.ts';\n\n/**\n * prototypes that can be manipulated with a plugin\n */\nconst PROTOTYPES: { [k: string]: any; } = {\n    RxSchema: RxSchema.prototype,\n    RxDocument: RxDocumentPrototype,\n    RxQuery: RxQueryBase.prototype,\n    RxCollection: RxCollectionBase.prototype,\n    RxDatabase: RxDatabaseBase.prototype\n};\n\nconst ADDED_PLUGINS: Set<RxPlugin | any> = new Set();\nconst ADDED_PLUGIN_NAMES: Set<string> = new Set();\n\n/**\n * Add a plugin to the RxDB library.\n * Plugins are added globally and cannot be removed.\n */\nexport function addRxPlugin(plugin: RxPlugin) {\n    runPluginHooks('preAddRxPlugin', { plugin, plugins: ADDED_PLUGINS });\n\n    // do nothing if added before\n    if (ADDED_PLUGINS.has(plugin)) {\n        return;\n    } else {\n\n        // ensure no other plugin with the same name was already added\n        if (ADDED_PLUGIN_NAMES.has(plugin.name)) {\n            throw newRxError('PL3', {\n                name: plugin.name,\n                plugin,\n            });\n        }\n\n        ADDED_PLUGINS.add(plugin);\n        ADDED_PLUGIN_NAMES.add(plugin.name);\n    }\n\n    /**\n     * To identify broken configurations,\n     * we only allow RxDB plugins to be passed into addRxPlugin().\n     */\n    if (!plugin.rxdb) {\n        throw newRxTypeError('PL1', {\n            plugin\n        });\n    }\n\n    if (plugin.init) {\n        plugin.init();\n    }\n\n    // prototype-overwrites\n    if (plugin.prototypes) {\n        Object\n            .entries(plugin.prototypes)\n            .forEach(([name, fun]) => {\n                return (fun as any)(PROTOTYPES[name]);\n            });\n    }\n    // overwritable-overwrites\n    if (plugin.overwritable) {\n        Object.assign(\n            overwritable,\n            plugin.overwritable\n        );\n    }\n    // extend-hooks\n    if (plugin.hooks) {\n        Object\n            .entries(plugin.hooks)\n            .forEach(([name, hooksObj]) => {\n                if (hooksObj.after) {\n                    (HOOKS as any)[name].push(hooksObj.after);\n                }\n                if (hooksObj.before) {\n                    (HOOKS as any)[name].unshift(hooksObj.before);\n                }\n            });\n    }\n}\n\n", "import { getComposedPrimaryKeyOfDocumentData } from '../rx-schema-helper.ts';\nimport { getWrittenDocumentsFromBulkWriteResponse, stackCheckpoints } from '../rx-storage-helper.ts';\nimport type {\n    RxDocumentData,\n    RxStorageInstanceReplicationInput,\n    RxStorageInstanceReplicationState,\n    RxStorageReplicationDirection,\n    RxStorageReplicationMeta\n} from '../types/index.d.ts';\nimport {\n    createRevision,\n    ensureNotFalsy,\n    getDefaultRevision,\n    getDefaultRxDocumentMeta,\n    now\n} from '../plugins/utils/index.ts';\n\nexport async function getLastCheckpointDoc<RxDocType, CheckpointType>(\n    state: RxStorageInstanceReplicationState<RxDocType>,\n    direction: RxStorageReplicationDirection\n): Promise<undefined | CheckpointType> {\n    const checkpointDocId = getComposedPrimaryKeyOfDocumentData(\n        state.input.metaInstance.schema,\n        {\n            isCheckpoint: '1',\n            itemId: direction\n        }\n    );\n    const checkpointResult = await state.input.metaInstance.findDocumentsById(\n        [\n            checkpointDocId\n        ],\n        false\n    );\n\n    const checkpointDoc = checkpointResult[0];\n    state.lastCheckpointDoc[direction] = checkpointDoc;\n    if (checkpointDoc) {\n        return checkpointDoc.checkpointData;\n    } else {\n        return undefined;\n    }\n}\n\n\n/**\n * Sets the checkpoint,\n * automatically resolves conflicts that appear.\n */\nexport async function setCheckpoint<RxDocType, CheckpointType>(\n    state: RxStorageInstanceReplicationState<RxDocType>,\n    direction: RxStorageReplicationDirection,\n    checkpoint: CheckpointType\n) {\n    state.checkpointQueue = state.checkpointQueue.then(async () => {\n        let previousCheckpointDoc = state.lastCheckpointDoc[direction];\n        if (\n            checkpoint &&\n            /**\n             * If the replication is already canceled,\n             * we do not write a checkpoint\n             * because that could mean we write a checkpoint\n             * for data that has been fetched from the master\n             * but not been written to the child.\n             */\n            !state.events.canceled.getValue() &&\n            /**\n             * Only write checkpoint if it is different from before\n             * to have less writes to the storage.\n             */\n            (\n                !previousCheckpointDoc ||\n                JSON.stringify(previousCheckpointDoc.checkpointData) !== JSON.stringify(checkpoint)\n            )\n        ) {\n            const newDoc: RxDocumentData<RxStorageReplicationMeta<RxDocType, CheckpointType>> = {\n                id: '',\n                isCheckpoint: '1',\n                itemId: direction,\n                _deleted: false,\n                _attachments: {},\n                checkpointData: checkpoint,\n                _meta: getDefaultRxDocumentMeta(),\n                _rev: getDefaultRevision()\n            };\n            newDoc.id = getComposedPrimaryKeyOfDocumentData(\n                state.input.metaInstance.schema,\n                newDoc\n            );\n            while (!state.events.canceled.getValue()) {\n                /**\n                 * Instead of just storing the new checkpoint,\n                 * we have to stack up the checkpoint with the previous one.\n                 * This is required for plugins like the sharding RxStorage\n                 * where the changeStream events only contain a Partial of the\n                 * checkpoint.\n                 */\n                if (previousCheckpointDoc) {\n                    newDoc.checkpointData = stackCheckpoints([\n                        previousCheckpointDoc.checkpointData,\n                        newDoc.checkpointData\n                    ]);\n                }\n                newDoc._meta.lwt = now();\n                newDoc._rev = createRevision(\n                    await state.checkpointKey,\n                    previousCheckpointDoc\n                );\n\n                if (state.events.canceled.getValue()) {\n                    return;\n                }\n\n                const writeRows = [{\n                    previous: previousCheckpointDoc,\n                    document: newDoc\n                }];\n                const result = await state.input.metaInstance.bulkWrite(writeRows, 'replication-set-checkpoint');\n                const successDoc = getWrittenDocumentsFromBulkWriteResponse(\n                    state.primaryPath,\n                    writeRows,\n                    result\n                )[0];\n                if (successDoc) {\n                    state.lastCheckpointDoc[direction] = successDoc;\n                    return;\n                } else {\n                    const error = result.error[0];\n                    if (error.status !== 409) {\n                        throw error;\n                    } else {\n                        previousCheckpointDoc = ensureNotFalsy(error.documentInDb);\n                        newDoc._rev = createRevision(\n                            await state.checkpointKey,\n                            previousCheckpointDoc\n                        );\n                    }\n                }\n            }\n        }\n    });\n    await state.checkpointQueue;\n}\n\nexport async function getCheckpointKey<RxDocType>(\n    input: RxStorageInstanceReplicationInput<RxDocType>\n): Promise<string> {\n    const hash = await input.hashFunction([\n        input.identifier,\n        input.forkInstance.databaseName,\n        input.forkInstance.collectionName\n    ].join('||'));\n    return 'rx_storage_replication_' + hash;\n}\n", "import type {\n    BulkWriteRow,\n    RxDocumentData,\n    RxDocumentWriteData,\n    RxStorageInstance,\n    RxStorageInstanceReplicationState,\n    RxStorageReplicationMeta,\n    WithDeletedAndAttachments\n} from '../types/index.d.ts';\nimport {\n    clone,\n    createRevision,\n    flatClone,\n    getDefaultRevision,\n    now\n} from '../plugins/utils/index.ts';\nimport { stripAttachmentsDataFromDocument } from '../rx-storage-helper.ts';\n\nexport function docStateToWriteDoc<RxDocType>(\n    databaseInstanceToken: string,\n    hasAttachments: boolean,\n    keepMeta: boolean,\n    docState: WithDeletedAndAttachments<RxDocType>,\n    previous?: RxDocumentData<RxDocType>\n): RxDocumentWriteData<RxDocType> {\n    const docData: RxDocumentWriteData<RxDocType> = Object.assign(\n        {},\n        docState,\n        {\n            _attachments: hasAttachments && docState._attachments ? docState._attachments : {},\n            _meta: keepMeta ? (docState as any)._meta : Object.assign(\n                {},\n                previous ? previous._meta : {},\n                {\n                    lwt: now()\n                }\n            ),\n            _rev: keepMeta ? (docState as any)._rev : getDefaultRevision()\n        }\n    );\n    if (!docData._rev) {\n        docData._rev = createRevision(\n            databaseInstanceToken,\n            previous\n        );\n    }\n\n    return docData;\n}\n\nexport function writeDocToDocState<RxDocType>(\n    writeDoc: RxDocumentData<RxDocType>,\n    keepAttachments: boolean,\n    keepMeta: boolean\n): WithDeletedAndAttachments<RxDocType> {\n    const ret = flatClone(writeDoc);\n\n    if (!keepAttachments) {\n        delete (ret as any)._attachments;\n    }\n    if (!keepMeta) {\n        delete (ret as any)._meta;\n        delete (ret as any)._rev;\n    }\n    return ret;\n}\n\n\nexport function stripAttachmentsDataFromMetaWriteRows<RxDocType>(\n    state: RxStorageInstanceReplicationState<any>,\n    rows: BulkWriteRow<RxStorageReplicationMeta<RxDocType, any>>[]\n): BulkWriteRow<RxStorageReplicationMeta<RxDocType, any>>[] {\n    if (!state.hasAttachments) {\n        return rows;\n    }\n    return rows.map(row => {\n        const document = clone(row.document);\n        document.docData = stripAttachmentsDataFromDocument(document.docData);\n        return {\n            document,\n            previous: row.previous\n        };\n    });\n}\n\nexport function getUnderlyingPersistentStorage<RxDocType>(\n    instance: RxStorageInstance<RxDocType, any, any, any>\n): RxStorageInstance<RxDocType, any, any, any> {\n    while (true) {\n        if (instance.underlyingPersistentStorage) {\n            instance = instance.underlyingPersistentStorage;\n        } else {\n            return instance;\n        }\n    }\n}\n", "import {\n    fillWithDefaultSettings,\n    getComposedPrimaryKeyOfDocumentData,\n    getLengthOfPrimaryKey\n} from '../rx-schema-helper.ts';\nimport { flatCloneDocWithMeta } from '../rx-storage-helper.ts';\nimport type {\n    BulkWriteRow,\n    ById,\n    RxDocumentData,\n    RxJsonSchema,\n    RxStorageInstanceReplicationState,\n    RxStorageReplicationMeta,\n    WithDeleted\n} from '../types/index.d.ts';\nimport {\n    getDefaultRevision,\n    createRevision,\n    now\n} from '../plugins/utils/index.ts';\n\n\nexport const META_INSTANCE_SCHEMA_TITLE = 'RxReplicationProtocolMetaData';\n\nexport function getRxReplicationMetaInstanceSchema<RxDocType, CheckpointType>(\n    replicatedDocumentsSchema: RxJsonSchema<RxDocumentData<RxDocType>>,\n    encrypted: boolean\n): RxJsonSchema<RxDocumentData<RxStorageReplicationMeta<RxDocType, CheckpointType>>> {\n    const parentPrimaryKeyLength = getLengthOfPrimaryKey(replicatedDocumentsSchema);\n\n    const baseSchema: RxJsonSchema<RxStorageReplicationMeta<RxDocType, CheckpointType>> = {\n        title: META_INSTANCE_SCHEMA_TITLE,\n        primaryKey: {\n            key: 'id',\n            fields: [\n                'itemId',\n                'isCheckpoint'\n            ],\n            separator: '|'\n        },\n        type: 'object',\n        version: replicatedDocumentsSchema.version,\n        additionalProperties: false,\n        properties: {\n            id: {\n                type: 'string',\n                minLength: 1,\n                // add +1 for the '|' and +1 for the 'isCheckpoint' flag\n                maxLength: parentPrimaryKeyLength + 2\n            },\n            isCheckpoint: {\n                type: 'string',\n                enum: [\n                    '0',\n                    '1'\n                ],\n                minLength: 1,\n                maxLength: 1\n            },\n            itemId: {\n                type: 'string',\n                /**\n                 * ensure that all values of RxStorageReplicationDirection ('DOWN' has 4 chars) fit into it\n                 * because checkpoints use the itemId field for that.\n                 */\n                maxLength: parentPrimaryKeyLength > 4 ? parentPrimaryKeyLength : 4\n            },\n            checkpointData: {\n                type: 'object',\n                additionalProperties: true\n            },\n            docData: {\n                type: 'object',\n                properties: replicatedDocumentsSchema.properties\n            },\n            isResolvedConflict: {\n                type: 'string'\n            }\n        },\n        keyCompression: replicatedDocumentsSchema.keyCompression,\n        required: [\n            'id',\n            'isCheckpoint',\n            'itemId'\n        ]\n    };\n    if (encrypted) {\n        baseSchema.encrypted = ['docData'];\n    }\n    const metaInstanceSchema: RxJsonSchema<RxDocumentData<RxStorageReplicationMeta<RxDocType, CheckpointType>>> = fillWithDefaultSettings(baseSchema);\n    return metaInstanceSchema;\n}\n\n\n\n/**\n * Returns the document states of what the fork instance\n * assumes to be the latest state on the master instance.\n */\nexport function getAssumedMasterState<RxDocType>(\n    state: RxStorageInstanceReplicationState<RxDocType>,\n    docIds: string[]\n): Promise<ById<{\n    docData: WithDeleted<RxDocType>;\n    metaDocument: RxDocumentData<RxStorageReplicationMeta<RxDocType, any>>;\n}>> {\n    return state.input.metaInstance.findDocumentsById(\n        docIds.map(docId => {\n            const useId = getComposedPrimaryKeyOfDocumentData(\n                state.input.metaInstance.schema,\n                {\n                    itemId: docId,\n                    isCheckpoint: '0'\n                }\n            );\n            return useId;\n        }),\n        true\n    ).then(metaDocs => {\n        const ret: {\n            [docId: string]: {\n                docData: RxDocumentData<RxDocType>;\n                metaDocument: RxDocumentData<RxStorageReplicationMeta<RxDocType, any>>;\n            };\n        } = {};\n        Object\n            .values(metaDocs)\n            .forEach((metaDoc) => {\n                ret[metaDoc.itemId] = {\n                    docData: metaDoc.docData,\n                    metaDocument: metaDoc\n                };\n            });\n\n        return ret;\n    });\n}\n\n\nexport async function getMetaWriteRow<RxDocType>(\n    state: RxStorageInstanceReplicationState<RxDocType>,\n    newMasterDocState: WithDeleted<RxDocType>,\n    previous?: RxDocumentData<RxStorageReplicationMeta<RxDocType, any>>,\n    isResolvedConflict?: string\n): Promise<BulkWriteRow<RxStorageReplicationMeta<RxDocType, any>>> {\n    const docId: string = (newMasterDocState as any)[state.primaryPath];\n    const newMeta: RxDocumentData<RxStorageReplicationMeta<RxDocType, any>> = previous ? flatCloneDocWithMeta(\n        previous\n    ) : {\n        id: '',\n        isCheckpoint: '0',\n        itemId: docId,\n        docData: newMasterDocState,\n        _attachments: {},\n        _deleted: false,\n        _rev: getDefaultRevision(),\n        _meta: {\n            lwt: 0\n        }\n    };\n    newMeta.docData = newMasterDocState;\n\n    /**\n     * Sending isResolvedConflict with the value undefined\n     * will throw a schema validation error because it must be either\n     * not set or have a string.\n     */\n    if (isResolvedConflict) {\n        newMeta.isResolvedConflict = isResolvedConflict;\n    }\n\n    newMeta._meta.lwt = now();\n    newMeta.id = getComposedPrimaryKeyOfDocumentData(\n        state.input.metaInstance.schema,\n        newMeta\n    );\n    newMeta._rev = createRevision(\n        await state.checkpointKey,\n        previous\n    );\n\n    const ret = {\n        previous,\n        document: newMeta\n    };\n\n    return ret;\n}\n", "import {\n    firstValueFrom,\n    filter,\n    mergeMap\n} from 'rxjs';\nimport { newRxError } from '../rx-error.ts';\nimport { getWrittenDocumentsFromBulkWriteResponse, stackCheckpoints } from '../rx-storage-helper.ts';\nimport type {\n    RxStorageInstanceReplicationState,\n    BulkWriteRow,\n    BulkWriteRowById,\n    RxStorageReplicationMeta,\n    RxDocumentData,\n    ById,\n    WithDeleted,\n    DocumentsWithCheckpoint,\n    WithDeletedAndAttachments,\n    RxError\n} from '../types/index.d.ts';\nimport {\n    appendToArray,\n    createRevision,\n    ensureNotFalsy,\n    flatClone,\n    getDefaultRevision,\n    getHeightOfRevision,\n    now,\n    PROMISE_RESOLVE_VOID\n} from '../plugins/utils/index.ts';\nimport {\n    getLastCheckpointDoc,\n    setCheckpoint\n} from './checkpoint.ts';\nimport {\n    stripAttachmentsDataFromMetaWriteRows,\n    writeDocToDocState\n} from './helper.ts';\nimport {\n    getAssumedMasterState,\n    getMetaWriteRow\n} from './meta-instance.ts';\n\n/**\n * Writes all documents from the master to the fork.\n * The downstream has two operation modes\n * - Sync by iterating over the checkpoints via downstreamResyncOnce()\n * - Sync by listening to the changestream via downstreamProcessChanges()\n * We need this to be able to do initial syncs\n * and still can have fast event based sync when the client is not offline.\n */\nexport async function startReplicationDownstream<RxDocType, CheckpointType = any>(\n    state: RxStorageInstanceReplicationState<RxDocType>\n) {\n    if (\n        state.input.initialCheckpoint &&\n        state.input.initialCheckpoint.downstream\n    ) {\n        const checkpointDoc = await getLastCheckpointDoc(state, 'down');\n        if (!checkpointDoc) {\n            await setCheckpoint(\n                state,\n                'down',\n                state.input.initialCheckpoint.downstream\n            );\n        }\n    }\n\n    const identifierHash = await state.input.hashFunction(state.input.identifier);\n    const replicationHandler = state.input.replicationHandler;\n\n    // used to detect which tasks etc can in it at which order.\n    let timer = 0;\n\n\n    type Task = DocumentsWithCheckpoint<RxDocType, any> | 'RESYNC';\n    type TaskWithTime = {\n        time: number;\n        task: Task;\n    };\n    const openTasks: TaskWithTime[] = [];\n\n\n    function addNewTask(task: Task): void {\n        state.stats.down.addNewTask = state.stats.down.addNewTask + 1;\n        const taskWithTime = {\n            time: timer++,\n            task\n        };\n        openTasks.push(taskWithTime);\n        state.streamQueue.down = state.streamQueue.down\n            .then(() => {\n                const useTasks: Task[] = [];\n                while (openTasks.length > 0) {\n                    state.events.active.down.next(true);\n                    const innerTaskWithTime = ensureNotFalsy(openTasks.shift());\n\n                    /**\n                     * If the task came in before the last time we started the pull\n                     * from the master, then we can drop the task.\n                     */\n                    if (innerTaskWithTime.time < lastTimeMasterChangesRequested) {\n                        continue;\n                    }\n\n                    if (innerTaskWithTime.task === 'RESYNC') {\n                        if (useTasks.length === 0) {\n                            useTasks.push(innerTaskWithTime.task);\n                            break;\n                        } else {\n                            break;\n                        }\n                    }\n\n                    useTasks.push(innerTaskWithTime.task);\n                }\n                if (useTasks.length === 0) {\n                    return;\n                }\n\n                if (useTasks[0] === 'RESYNC') {\n                    return downstreamResyncOnce();\n                } else {\n                    return downstreamProcessChanges(useTasks);\n                }\n            }).then(() => {\n                state.events.active.down.next(false);\n                if (\n                    !state.firstSyncDone.down.getValue() &&\n                    !state.events.canceled.getValue()\n                ) {\n                    state.firstSyncDone.down.next(true);\n                }\n            });\n    }\n    addNewTask('RESYNC');\n\n    /**\n     * If a write on the master happens, we have to trigger the downstream.\n     * Only do this if not canceled yet, otherwise firstValueFrom errors\n     * when running on a completed observable.\n     */\n    if (!state.events.canceled.getValue()) {\n        const sub = replicationHandler\n            .masterChangeStream$\n            .pipe(\n                mergeMap(async (ev) => {\n                    /**\n                     * While a push is running, we have to delay all incoming\n                     * events from the server to not mix up the replication state.\n                     */\n                    await firstValueFrom(\n                        state.events.active.up.pipe(filter(s => !s))\n                    );\n                    return ev;\n                })\n            )\n            .subscribe((task: Task) => {\n                state.stats.down.masterChangeStreamEmit = state.stats.down.masterChangeStreamEmit + 1;\n                addNewTask(task);\n            });\n        // unsubscribe when replication is canceled\n        firstValueFrom(\n            state.events.canceled.pipe(\n                filter(canceled => !!canceled)\n            )\n        ).then(() => sub.unsubscribe());\n    }\n\n\n    /**\n     * For faster performance, we directly start each write\n     * and then await all writes at the end.\n     */\n    let lastTimeMasterChangesRequested: number = -1;\n    async function downstreamResyncOnce() {\n        state.stats.down.downstreamResyncOnce = state.stats.down.downstreamResyncOnce + 1;\n        if (state.events.canceled.getValue()) {\n            return;\n        }\n\n        state.checkpointQueue = state.checkpointQueue.then(() => getLastCheckpointDoc(state, 'down'));\n        let lastCheckpoint: CheckpointType = await state.checkpointQueue;\n\n\n        const promises: Promise<any>[] = [];\n        while (!state.events.canceled.getValue()) {\n            lastTimeMasterChangesRequested = timer++;\n            const downResult = await replicationHandler.masterChangesSince(\n                lastCheckpoint,\n                state.input.pullBatchSize\n            );\n\n            if (downResult.documents.length === 0) {\n                break;\n            }\n\n            lastCheckpoint = stackCheckpoints([lastCheckpoint, downResult.checkpoint]);\n\n            promises.push(\n                persistFromMaster(\n                    downResult.documents,\n                    lastCheckpoint\n                )\n            );\n\n            /**\n             * By definition we stop pull when the pulled documents\n             * do not fill up the pullBatchSize because we\n             * can assume that the remote has no more documents.\n             */\n            if (downResult.documents.length < state.input.pullBatchSize) {\n                break;\n            }\n\n        }\n        await Promise.all(promises);\n    }\n\n\n    function downstreamProcessChanges(tasks: Task[]) {\n        state.stats.down.downstreamProcessChanges = state.stats.down.downstreamProcessChanges + 1;\n        const docsOfAllTasks: WithDeleted<RxDocType>[] = [];\n        let lastCheckpoint: CheckpointType | undefined = null as any;\n\n        tasks.forEach(task => {\n            if (task === 'RESYNC') {\n                throw new Error('SNH');\n            }\n            appendToArray(docsOfAllTasks, task.documents);\n            lastCheckpoint = stackCheckpoints([lastCheckpoint, task.checkpoint]);\n        });\n        return persistFromMaster(\n            docsOfAllTasks,\n            ensureNotFalsy(lastCheckpoint)\n        );\n    }\n\n\n    /**\n     * It can happen that the calls to masterChangesSince() or the changeStream()\n     * are way faster then how fast the documents can be persisted.\n     * Therefore we merge all incoming downResults into the nonPersistedFromMaster object\n     * and process them together if possible.\n     * This often bundles up single writes and improves performance\n     * by processing the documents in bulks.\n     */\n    let persistenceQueue = PROMISE_RESOLVE_VOID;\n    const nonPersistedFromMaster: {\n        checkpoint?: CheckpointType;\n        docs: ById<WithDeleted<RxDocType>>;\n    } = {\n        docs: {}\n    };\n\n    function persistFromMaster(\n        docs: WithDeleted<RxDocType>[],\n        checkpoint: CheckpointType\n    ): Promise<void> {\n        const primaryPath = state.primaryPath;\n        state.stats.down.persistFromMaster = state.stats.down.persistFromMaster + 1;\n\n        /**\n         * Add the new docs to the non-persistent list\n         */\n        docs.forEach(docData => {\n            const docId: string = (docData as any)[primaryPath];\n            nonPersistedFromMaster.docs[docId] = docData;\n        });\n        nonPersistedFromMaster.checkpoint = checkpoint;\n\n        /**\n         * Run in the queue\n         * with all open documents from nonPersistedFromMaster.\n         */\n        persistenceQueue = persistenceQueue.then(() => {\n            const downDocsById: ById<WithDeletedAndAttachments<RxDocType>> = nonPersistedFromMaster.docs;\n            nonPersistedFromMaster.docs = {};\n            const useCheckpoint = nonPersistedFromMaster.checkpoint;\n            const docIds = Object.keys(downDocsById);\n\n            if (\n                state.events.canceled.getValue() ||\n                docIds.length === 0\n            ) {\n                return PROMISE_RESOLVE_VOID;\n            }\n\n            const writeRowsToFork: BulkWriteRow<RxDocType>[] = [];\n            const writeRowsToForkById: ById<BulkWriteRow<RxDocType>> = {};\n            const writeRowsToMeta: BulkWriteRowById<RxStorageReplicationMeta<RxDocType, CheckpointType>> = {};\n            const useMetaWriteRows: BulkWriteRow<RxStorageReplicationMeta<RxDocType, CheckpointType>>[] = [];\n\n            return Promise.all([\n                state.input.forkInstance.findDocumentsById(docIds, true),\n                getAssumedMasterState(\n                    state,\n                    docIds\n                )\n            ]).then(([\n                currentForkStateList,\n                assumedMasterState\n            ]) => {\n                const currentForkState = new Map<string, RxDocumentData<RxDocType>>();\n                currentForkStateList.forEach(doc => currentForkState.set((doc as any)[primaryPath], doc));\n                return Promise.all(\n                    docIds.map(async (docId) => {\n                        const forkStateFullDoc: RxDocumentData<RxDocType> | undefined = currentForkState.get(docId);\n                        const forkStateDocData: WithDeletedAndAttachments<RxDocType> | undefined = forkStateFullDoc\n                            ? writeDocToDocState(forkStateFullDoc, state.hasAttachments, false)\n                            : undefined\n                            ;\n                        const masterState = downDocsById[docId];\n                        const assumedMaster = assumedMasterState[docId];\n\n                        if (\n                            assumedMaster &&\n                            forkStateFullDoc &&\n                            assumedMaster.metaDocument.isResolvedConflict === forkStateFullDoc._rev\n                        ) {\n                            /**\n                             * The current fork state represents a resolved conflict\n                             * that first must be send to the master in the upstream.\n                             * All conflicts are resolved by the upstream.\n                             */\n                            // return PROMISE_RESOLVE_VOID;\n                            await state.streamQueue.up;\n                        }\n\n                        let isAssumedMasterEqualToForkState = !assumedMaster || !forkStateDocData ?\n                            false :\n                            state.input.conflictHandler.isEqual(\n                                assumedMaster.docData,\n                                forkStateDocData,\n                                'downstream-check-if-equal-0'\n                            );\n                        if (\n                            !isAssumedMasterEqualToForkState &&\n                            (\n                                assumedMaster &&\n                                (assumedMaster.docData as any)._rev &&\n                                forkStateFullDoc &&\n                                forkStateFullDoc._meta[state.input.identifier] &&\n                                getHeightOfRevision(forkStateFullDoc._rev) === forkStateFullDoc._meta[state.input.identifier]\n                            )\n                        ) {\n                            isAssumedMasterEqualToForkState = true;\n                        }\n                        if (\n                            (\n                                forkStateFullDoc &&\n                                assumedMaster &&\n                                isAssumedMasterEqualToForkState === false\n                            ) ||\n                            (\n                                forkStateFullDoc && !assumedMaster\n                            )\n                        ) {\n                            /**\n                             * We have a non-upstream-replicated\n                             * local write to the fork.\n                             * This means we ignore the downstream of this document\n                             * because anyway the upstream will first resolve the conflict.\n                             */\n                            return PROMISE_RESOLVE_VOID;\n                        }\n\n                        const areStatesExactlyEqual = !forkStateDocData\n                            ? false\n                            : state.input.conflictHandler.isEqual(\n                                masterState,\n                                forkStateDocData,\n                                'downstream-check-if-equal-1'\n                            );\n                        if (\n                            forkStateDocData &&\n                            areStatesExactlyEqual\n                        ) {\n                            /**\n                             * Document states are exactly equal.\n                             * This can happen when the replication is shut down\n                             * unexpected like when the user goes offline.\n                             *\n                             * Only when the assumedMaster is different from the forkState,\n                             * we have to patch the document in the meta instance.\n                             */\n                            if (\n                                !assumedMaster ||\n                                isAssumedMasterEqualToForkState === false\n                            ) {\n                                useMetaWriteRows.push(\n                                    await getMetaWriteRow(\n                                        state,\n                                        forkStateDocData,\n                                        assumedMaster ? assumedMaster.metaDocument : undefined\n                                    )\n                                );\n                            }\n                            return PROMISE_RESOLVE_VOID;\n                        }\n\n                        /**\n                         * All other master states need to be written to the forkInstance\n                         * and metaInstance.\n                         */\n                        const newForkState = Object.assign(\n                            {},\n                            masterState,\n                            forkStateFullDoc ? {\n                                _meta: flatClone(forkStateFullDoc._meta),\n                                _attachments: state.hasAttachments && masterState._attachments ? masterState._attachments : {},\n                                _rev: getDefaultRevision()\n                            } : {\n                                _meta: {\n                                    lwt: now()\n                                },\n                                _rev: getDefaultRevision(),\n                                _attachments: state.hasAttachments && masterState._attachments ? masterState._attachments : {}\n                            }\n                        );\n                        /**\n                         * If the remote works with revisions,\n                         * we store the height of the next fork-state revision\n                         * inside of the documents meta data.\n                         * By doing so we can filter it out in the upstream\n                         * and detect the document as being equal to master or not.\n                         * This is used for example in the CouchDB replication plugin.\n                         */\n                        if ((masterState as any)._rev) {\n                            const nextRevisionHeight = !forkStateFullDoc ? 1 : getHeightOfRevision(forkStateFullDoc._rev) + 1;\n                            newForkState._meta[state.input.identifier] = nextRevisionHeight;\n                            if (state.input.keepMeta) {\n                                newForkState._rev = (masterState as any)._rev;\n                            }\n                        }\n                        if (\n                            state.input.keepMeta &&\n                            (masterState as any)._meta\n                        ) {\n                            newForkState._meta = (masterState as any)._meta;\n                        }\n\n                        const forkWriteRow = {\n                            previous: forkStateFullDoc,\n                            document: newForkState\n                        };\n\n                        forkWriteRow.document._rev = forkWriteRow.document._rev ? forkWriteRow.document._rev : createRevision(\n                            identifierHash,\n                            forkWriteRow.previous\n                        );\n                        writeRowsToFork.push(forkWriteRow);\n                        writeRowsToForkById[docId] = forkWriteRow;\n                        writeRowsToMeta[docId] = await getMetaWriteRow(\n                            state,\n                            masterState,\n                            assumedMaster ? assumedMaster.metaDocument : undefined\n                        );\n                    })\n                );\n            }).then(async () => {\n                if (writeRowsToFork.length > 0) {\n                    return state.input.forkInstance.bulkWrite(\n                        writeRowsToFork,\n                        await state.downstreamBulkWriteFlag\n                    ).then((forkWriteResult) => {\n                        const success = getWrittenDocumentsFromBulkWriteResponse(\n                            state.primaryPath,\n                            writeRowsToFork,\n                            forkWriteResult\n                        );\n                        success.forEach(doc => {\n                            const docId = (doc as any)[primaryPath];\n                            state.events.processed.down.next(writeRowsToForkById[docId]);\n                            useMetaWriteRows.push(writeRowsToMeta[docId]);\n                        });\n                        let mustThrow: RxError | undefined;\n                        forkWriteResult.error.forEach(error => {\n                            /**\n                             * We do not have to care about downstream conflict errors here\n                             * because on conflict, it will be solved locally and result in another write.\n                             */\n                            if (error.status === 409) {\n                                return;\n                            }\n                            // other non-conflict errors must be handled\n                            const throwMe = newRxError('RC_PULL', {\n                                writeError: error\n                            });\n                            state.events.error.next(throwMe);\n                            mustThrow = throwMe;\n                        });\n                        if (mustThrow) {\n                            throw mustThrow;\n                        }\n                    });\n                }\n            }).then(() => {\n                if (useMetaWriteRows.length > 0) {\n                    return state.input.metaInstance.bulkWrite(\n                        stripAttachmentsDataFromMetaWriteRows(state, useMetaWriteRows),\n                        'replication-down-write-meta'\n                    ).then(metaWriteResult => {\n                        metaWriteResult.error\n                            .forEach(writeError => {\n                                state.events.error.next(newRxError('RC_PULL', {\n                                    id: writeError.documentId,\n                                    writeError\n                                }));\n                            });\n                    });\n                }\n            }).then(() => {\n                /**\n                 * For better performance we do not await checkpoint writes,\n                 * but to ensure order on parallel checkpoint writes,\n                 * we have to use a queue.\n                 */\n                setCheckpoint(\n                    state,\n                    'down',\n                    useCheckpoint\n                );\n            });\n        }).catch(unhandledError => state.events.error.next(unhandledError));\n        return persistenceQueue;\n    }\n}\n", "import type {\n    RxConflictHandler,\n    RxConflictHandlerInput,\n    RxDocumentData,\n    RxStorageInstanceReplicationState\n} from '../types/index.d.ts';\nimport {\n    getDefaultRevision,\n    createRevision,\n    now,\n    flatClone\n} from '../plugins/utils/index.ts';\n\n/**\n * Resolves a conflict error or determines that the given document states are equal.\n * Returns the resolved document that must be written to the fork.\n * Then the new document state can be pushed upstream.\n * If document is not in conflict, returns undefined.\n * If error is non-409, it throws an error.\n * Conflicts are only solved in the upstream, never in the downstream.\n */\nexport async function resolveConflictError<RxDocType>(\n    state: RxStorageInstanceReplicationState<RxDocType>,\n    input: RxConflictHandlerInput<RxDocType>,\n    forkState: RxDocumentData<RxDocType>\n): Promise<RxDocumentData<RxDocType> | undefined> {\n    const conflictHandler: RxConflictHandler<RxDocType> = state.input.conflictHandler;\n\n    const isEqual = conflictHandler.isEqual(input.realMasterState, input.newDocumentState, 'replication-resolve-conflict');\n\n    if (isEqual) {\n        /**\n         * Documents are equal,\n         * so this is not a conflict -> do nothing.\n         */\n        return undefined;\n    } else {\n        const resolved = await conflictHandler.resolve(input, 'replication-resolve-conflict');\n        /**\n         * We have a resolved conflict,\n         * use the resolved document data.\n         */\n        const resolvedDoc: RxDocumentData<RxDocType> = Object.assign(\n            {},\n            resolved,\n            {\n                /**\n                 * Because the resolved conflict is written to the fork,\n                 * we have to keep/update the forks _meta data, not the masters.\n                 */\n                _meta: flatClone(forkState._meta),\n                _rev: getDefaultRevision(),\n                _attachments: flatClone(forkState._attachments)\n            }\n        ) as any;\n        resolvedDoc._meta.lwt = now();\n        resolvedDoc._rev = createRevision(\n            await state.checkpointKey,\n            forkState\n        );\n        return resolvedDoc;\n    }\n}\n", "import { newRxError } from '../../rx-error.ts';\nimport type {\n    RxAttachmentWriteData,\n    RxStorageInstance,\n    WithDeletedAndAttachments\n} from '../../types/index.d.ts';\nimport { ensureNotFalsy } from '../utils/index.ts';\n\nexport function ensureSchemaSupportsAttachments(doc: any) {\n    const schemaJson = doc.collection.schema.jsonSchema;\n    if (!schemaJson.attachments) {\n        throw newRxError('AT1', {\n            link: 'https://pubkey.github.io/rxdb/rx-attachment.html'\n        });\n    }\n}\n\nexport function assignMethodsToAttachment(attachment: any) {\n    Object\n        .entries(attachment.doc.collection.attachments)\n        .forEach(([funName, fun]) => {\n            Object.defineProperty(attachment, funName, {\n                get: () => (fun as any).bind(attachment)\n            });\n        });\n}\n\n/**\n * Fill up the missing attachment.data of the newDocument\n * so that the new document can be send to somewhere else\n * which could then receive all required attachments data\n * that it did not have before.\n */\nexport async function fillWriteDataForAttachmentsChange<RxDocType>(\n    primaryPath: string,\n    storageInstance: RxStorageInstance<RxDocType, any, any, any>,\n    newDocument: WithDeletedAndAttachments<RxDocType>,\n    originalDocument?: WithDeletedAndAttachments<RxDocType>\n): Promise<WithDeletedAndAttachments<RxDocType>> {\n\n    if (\n        !newDocument._attachments ||\n        (\n            originalDocument &&\n            !originalDocument._attachments\n        )\n    ) {\n        throw new Error('_attachments missing');\n    }\n\n    const docId: string = (newDocument as any)[primaryPath];\n    const originalAttachmentsIds = new Set(\n        originalDocument && originalDocument._attachments\n            ? Object.keys(originalDocument._attachments)\n            : []\n    );\n    await Promise.all(\n        Object\n            .entries(newDocument._attachments)\n            .map(async ([key, value]) => {\n                if (\n                    (\n                        !originalAttachmentsIds.has(key) ||\n                        (\n                            originalDocument &&\n                            ensureNotFalsy(originalDocument._attachments)[key].digest !== value.digest\n                        )\n                    ) &&\n                    !(value as RxAttachmentWriteData).data\n                ) {\n                    const attachmentDataString = await storageInstance.getAttachmentData(\n                        docId,\n                        key,\n                        value.digest\n                    );\n                    (value as RxAttachmentWriteData).data = attachmentDataString;\n                }\n            })\n    );\n\n    return newDocument;\n}\n", "import {\n    map\n} from 'rxjs';\n\nimport {\n    blobToBase64String,\n    blobToString,\n    createBlobFromBase64,\n    flatClone,\n    getBlobSize,\n    PROMISE_RESOLVE_VOID\n} from '../../plugins/utils/index.ts';\nimport type {\n    RxDocument,\n    RxPlugin,\n    RxDocumentWriteData,\n    RxAttachmentData,\n    RxDocumentData,\n    RxAttachmentCreator,\n    RxAttachmentWriteData,\n    RxCollection,\n    RxAttachmentCreatorBase64\n} from '../../types/index.ts';\nimport {\n    assignMethodsToAttachment,\n    ensureSchemaSupportsAttachments\n} from './attachments-utils.ts';\n\n\n\n/**\n * an RxAttachment is basically just the attachment-stub\n * wrapped so that you can access the attachment-data\n */\nexport class RxAttachment {\n    public doc: RxDocument;\n    public id: string;\n    public type: string;\n    public length: number;\n    public digest: string;\n    constructor({\n        doc,\n        id,\n        type,\n        length,\n        digest\n    }: any) {\n        this.doc = doc;\n        this.id = id;\n        this.type = type;\n        this.length = length;\n        this.digest = digest;\n\n        assignMethodsToAttachment(this);\n    }\n\n    remove(): Promise<void> {\n        return this.doc.collection.incrementalWriteQueue.addWrite(\n            this.doc._data,\n            docWriteData => {\n                delete docWriteData._attachments[this.id];\n                return docWriteData;\n            }\n        ).then(() => { });\n    }\n\n    /**\n     * returns the data for the attachment\n     */\n    async getData(): Promise<Blob> {\n        const plainDataBase64 = await this.getDataBase64();\n        const ret = await createBlobFromBase64(\n            plainDataBase64,\n            this.type as any\n        );\n        return ret;\n    }\n\n    async getStringData(): Promise<string> {\n        const data = await this.getData();\n        const asString = await blobToString(data);\n        return asString;\n    }\n\n    async getDataBase64(): Promise<string> {\n        const plainDataBase64 = await this.doc.collection.storageInstance.getAttachmentData(\n            this.doc.primary,\n            this.id,\n            this.digest\n        );\n        return plainDataBase64;\n    }\n}\n\nexport function fromStorageInstanceResult<RxDocType>(\n    id: string,\n    attachmentData: RxAttachmentData,\n    rxDocument: RxDocument<RxDocType>\n) {\n    return new RxAttachment({\n        doc: rxDocument,\n        id,\n        type: attachmentData.type,\n        length: attachmentData.length,\n        digest: attachmentData.digest\n    });\n}\n\n\n\nexport async function putAttachment<RxDocType>(\n    this: RxDocument<RxDocType>,\n    attachmentData: RxAttachmentCreator\n): Promise<RxAttachment> {\n    ensureSchemaSupportsAttachments(this);\n\n    const dataSize = getBlobSize(attachmentData.data);\n    const dataString = await blobToBase64String(attachmentData.data);\n\n    return this.putAttachmentBase64({\n        id: attachmentData.id,\n        length: dataSize,\n        type: attachmentData.type,\n        data: dataString\n    }) as any;\n}\n\nexport async function putAttachmentBase64<RxDocType>(\n    this: RxDocument<RxDocType>,\n    attachmentData: RxAttachmentCreatorBase64\n) {\n    ensureSchemaSupportsAttachments(this);\n    const digest = await this.collection.database.hashFunction(attachmentData.data);\n\n    const id = attachmentData.id;\n    const type = attachmentData.type;\n    const data = attachmentData.data;\n\n    return this.collection.incrementalWriteQueue.addWrite(\n        this._data,\n        (docWriteData: RxDocumentWriteData<RxDocType>) => {\n            docWriteData = flatClone(docWriteData);\n            docWriteData._attachments = flatClone(docWriteData._attachments);\n            docWriteData._attachments[id] = {\n                length: attachmentData.length,\n                type,\n                data,\n                digest\n            };\n            return docWriteData;\n        }).then(writeResult => {\n            const newDocument = this.collection._docCache.getCachedRxDocument(writeResult);\n            const attachmentDataOfId = writeResult._attachments[id];\n            const attachment = fromStorageInstanceResult(\n                id,\n                attachmentDataOfId,\n                newDocument\n            );\n            return attachment;\n        });\n}\n\n/**\n * get an attachment of the document by its id\n */\nexport function getAttachment(\n    this: RxDocument,\n    id: string\n): RxAttachment | null {\n    ensureSchemaSupportsAttachments(this);\n    const docData: any = this._data;\n    if (!docData._attachments || !docData._attachments[id])\n        return null;\n\n    const attachmentData = docData._attachments[id];\n    const attachment = fromStorageInstanceResult(\n        id,\n        attachmentData,\n        this\n    );\n    return attachment;\n}\n\n/**\n * returns all attachments of the document\n */\nexport function allAttachments(\n    this: RxDocument\n): RxAttachment[] {\n    ensureSchemaSupportsAttachments(this);\n    const docData: any = this._data;\n\n    // if there are no attachments, the field is missing\n    if (!docData._attachments) {\n        return [];\n    }\n    return Object.keys(docData._attachments)\n        .map(id => {\n            return fromStorageInstanceResult(\n                id,\n                docData._attachments[id],\n                this\n            );\n        });\n}\n\nexport async function preMigrateDocument<RxDocType>(\n    data: {\n        docData: RxDocumentData<RxDocType>;\n        oldCollection: RxCollection<RxDocType>;\n    }\n): Promise<void> {\n    const attachments = data.docData._attachments;\n    if (attachments) {\n        const newAttachments: { [attachmentId: string]: RxAttachmentWriteData; } = {};\n        await Promise.all(\n            Object.keys(attachments).map(async (attachmentId) => {\n                const attachment: RxAttachmentData = attachments[attachmentId];\n                const docPrimary: string = (data.docData as any)[data.oldCollection.schema.primaryPath];\n                const rawAttachmentData = await data.oldCollection.storageInstance.getAttachmentData(\n                    docPrimary,\n                    attachmentId,\n                    attachment.digest\n                );\n                const digest = await data.oldCollection.database.hashFunction(rawAttachmentData);\n                newAttachments[attachmentId] = {\n                    length: attachment.length,\n                    type: attachment.type,\n                    data: rawAttachmentData,\n                    digest\n                };\n            })\n        );\n\n        /**\n         * Hooks mutate the input\n         * instead of returning stuff\n         */\n        (data.docData as RxDocumentWriteData<RxDocType>)._attachments = newAttachments;\n    }\n}\n\nexport function postMigrateDocument(_action: any): Promise<void> {\n    /**\n     * No longer needed because\n     * we store the attachments data buffers directly in the document.\n     */\n    return PROMISE_RESOLVE_VOID;\n}\n\nexport const RxDBAttachmentsPlugin: RxPlugin = {\n    name: 'attachments',\n    rxdb: true,\n    prototypes: {\n        RxDocument: (proto: any) => {\n            proto.putAttachment = putAttachment;\n            proto.putAttachmentBase64 = putAttachmentBase64;\n            proto.getAttachment = getAttachment;\n            proto.allAttachments = allAttachments;\n            Object.defineProperty(proto, 'allAttachments$', {\n                get: function allAttachments$(this: RxDocument) {\n                    return this.$\n                        .pipe(\n                            map(rxDocument => Object.entries(\n                                rxDocument.toJSON(true)._attachments\n                            )),\n                            map(entries => {\n                                return (entries as any)\n                                    .map(([id, attachmentData]: any) => {\n                                        return fromStorageInstanceResult(\n                                            id,\n                                            attachmentData,\n                                            this\n                                        );\n                                    });\n                            })\n                        );\n                }\n            });\n        }\n    },\n    overwritable: {},\n    hooks: {\n        preMigrateDocument: {\n            after: preMigrateDocument\n        },\n        postMigrateDocument: {\n            after: postMigrateDocument\n        }\n    }\n};\n\n\nexport * from './attachments-utils.ts';\n", "import { firstValueFrom, filter } from 'rxjs';\nimport {\n    getChangedDocumentsSince,\n    getWrittenDocumentsFromBulkWriteResponse,\n    stackCheckpoints\n} from '../rx-storage-helper.ts';\nimport type {\n    BulkWriteRow,\n    BulkWriteRowById,\n    ById,\n    EventBulk,\n    RxDocumentData,\n    RxError,\n    RxReplicationWriteToMasterRow,\n    RxStorageChangeEvent,\n    RxStorageInstanceReplicationState,\n    RxStorageReplicationMeta,\n    WithDeleted\n} from '../types/index.d.ts';\nimport {\n    appendToArray,\n    batchArray,\n    clone,\n    ensureNotFalsy,\n    getHeightOfRevision,\n    PROMISE_RESOLVE_FALSE\n} from '../plugins/utils/index.ts';\nimport {\n    getLastCheckpointDoc,\n    setCheckpoint\n} from './checkpoint.ts';\nimport {\n    resolveConflictError\n} from './conflicts.ts';\nimport {\n    stripAttachmentsDataFromMetaWriteRows,\n    writeDocToDocState\n} from './helper.ts';\nimport {\n    getAssumedMasterState,\n    getMetaWriteRow\n} from './meta-instance.ts';\nimport { fillWriteDataForAttachmentsChange } from '../plugins/attachments/index.ts';\nimport { newRxError } from '../rx-error.ts';\n\n/**\n * Writes all document changes from the fork to the master.\n * The upstream runs on two modes:\n * - For initial replication, a checkpoint-iteration is used\n * - For ongoing local writes, we just subscribe to the changeStream of the fork.\n *   In contrast to the master, the fork can be assumed to never loose connection,\n *   so we do not have to prepare for missed out events.\n */\nexport async function startReplicationUpstream<RxDocType, CheckpointType>(\n    state: RxStorageInstanceReplicationState<RxDocType>\n) {\n    if (\n        state.input.initialCheckpoint &&\n        state.input.initialCheckpoint.upstream\n    ) {\n        const checkpointDoc = await getLastCheckpointDoc(state, 'up');\n        if (!checkpointDoc) {\n            await setCheckpoint(\n                state,\n                'up',\n                state.input.initialCheckpoint.upstream\n            );\n        }\n    }\n\n    const replicationHandler = state.input.replicationHandler;\n    state.streamQueue.up = state.streamQueue.up.then(() => {\n        return upstreamInitialSync().then(() => {\n            return processTasks();\n        });\n    });\n\n    // used to detect which tasks etc can in it at which order.\n    let timer = 0;\n    let initialSyncStartTime = -1;\n\n    type Task = EventBulk<RxStorageChangeEvent<RxDocType>, any> | 'RESYNC';\n    type TaskWithTime = {\n        task: Task;\n        time: number;\n    };\n    const openTasks: TaskWithTime[] = [];\n    let persistenceQueue: Promise<boolean> = PROMISE_RESOLVE_FALSE;\n    const nonPersistedFromMaster: {\n        checkpoint?: CheckpointType;\n        docs: ById<RxDocumentData<RxDocType>>;\n    } = {\n        docs: {}\n    };\n\n    const sub = state.input.forkInstance.changeStream()\n        .subscribe((eventBulk) => {\n            if (state.events.paused.getValue()) {\n                return;\n            }\n\n\n            state.stats.up.forkChangeStreamEmit = state.stats.up.forkChangeStreamEmit + 1;\n            openTasks.push({\n                task: eventBulk,\n                time: timer++\n            });\n            if (!state.events.active.up.getValue()) {\n                state.events.active.up.next(true);\n            }\n            if (state.input.waitBeforePersist) {\n                return state.input.waitBeforePersist()\n                    .then(() => processTasks());\n            } else {\n                return processTasks();\n            }\n        });\n    const subResync = replicationHandler\n        .masterChangeStream$\n        .pipe(\n            filter(ev => ev === 'RESYNC')\n        )\n        .subscribe(() => {\n            openTasks.push({\n                task: 'RESYNC',\n                time: timer++\n            });\n            processTasks();\n        });\n\n    // unsubscribe when replication is canceled\n    firstValueFrom(\n        state.events.canceled.pipe(\n            filter(canceled => !!canceled)\n        )\n    ).then(() => {\n        sub.unsubscribe();\n        subResync.unsubscribe();\n    });\n\n\n    async function upstreamInitialSync() {\n        state.stats.up.upstreamInitialSync = state.stats.up.upstreamInitialSync + 1;\n        if (state.events.canceled.getValue()) {\n            return;\n        }\n\n        state.checkpointQueue = state.checkpointQueue.then(() => getLastCheckpointDoc(state, 'up'));\n        let lastCheckpoint: CheckpointType = await state.checkpointQueue;\n\n        const promises: Set<Promise<any>> = new Set();\n\n        while (!state.events.canceled.getValue()) {\n            initialSyncStartTime = timer++;\n\n            /**\n             * Throttle the calls to\n             * forkInstance.getChangedDocumentsSince() so that\n             * if the pushing to the remote is slower compared to the\n             * pulling out of forkInstance, we do not block the UI too much\n             * and have a big memory spike with all forkInstance documents.\n             */\n            if (promises.size > 3) {\n                await Promise.race(Array.from(promises));\n            }\n            const upResult = await getChangedDocumentsSince(\n                state.input.forkInstance,\n                state.input.pushBatchSize,\n                lastCheckpoint\n            );\n            if (upResult.documents.length === 0) {\n                break;\n            }\n\n            lastCheckpoint = stackCheckpoints([lastCheckpoint, upResult.checkpoint]);\n\n            const promise = persistToMaster(\n                upResult.documents,\n                ensureNotFalsy(lastCheckpoint)\n            );\n            promises.add(promise);\n            promise.catch().then(() => promises.delete(promise));\n        }\n\n        /**\n         * If we had conflicts during the initial sync,\n         * it means that we likely have new writes to the fork\n         * and so we have to run the initial sync again to upstream these new writes.\n         */\n        const resolvedPromises = await Promise.all(promises);\n        const hadConflicts = resolvedPromises.find(r => !!r);\n        if (hadConflicts) {\n            await upstreamInitialSync();\n        } else if (\n            !state.firstSyncDone.up.getValue() &&\n            !state.events.canceled.getValue()\n        ) {\n            state.firstSyncDone.up.next(true);\n        }\n    }\n\n\n    /**\n     * Takes all open tasks an processes them at once.\n     */\n    function processTasks() {\n        if (\n            state.events.canceled.getValue() ||\n            openTasks.length === 0\n        ) {\n            state.events.active.up.next(false);\n            return;\n        }\n        state.stats.up.processTasks = state.stats.up.processTasks + 1;\n        state.events.active.up.next(true);\n        state.streamQueue.up = state.streamQueue.up.then(async () => {\n            /**\n             * Merge/filter all open tasks\n             */\n            const docs: RxDocumentData<RxDocType>[] = [];\n            let checkpoint: CheckpointType | undefined;\n            while (openTasks.length > 0) {\n                const taskWithTime = ensureNotFalsy(openTasks.shift());\n                /**\n                 * If the task came in before the last time the initial sync fetching\n                 * has run, we can ignore the task because the initial sync already processed\n                 * these documents.\n                 */\n                if (taskWithTime.time < initialSyncStartTime) {\n                    continue;\n                }\n\n                if (taskWithTime.task === 'RESYNC') {\n                    state.events.active.up.next(false);\n                    await upstreamInitialSync();\n                    return;\n                }\n\n                /**\n                 * If the task came from the downstream, we can ignore these documents\n                 * because we know they are replicated already.\n                 * But even if they can be ignored, we later have to call persistToMaster()\n                 * to have the correct checkpoint set.\n                 */\n                if (taskWithTime.task.context !== await state.downstreamBulkWriteFlag) {\n                    appendToArray(\n                        docs,\n                        taskWithTime.task.events.map(r => {\n                            return r.documentData as any;\n                        })\n                    );\n                }\n                checkpoint = stackCheckpoints([checkpoint, taskWithTime.task.checkpoint]);\n            }\n\n            await persistToMaster(\n                docs,\n                checkpoint as any\n            );\n\n            // might have got more tasks while running persistToMaster()\n            if (openTasks.length === 0) {\n                state.events.active.up.next(false);\n            } else {\n                return processTasks();\n            }\n        });\n    }\n\n    /**\n     * Returns true if had conflicts,\n     * false if not.\n     */\n    function persistToMaster(\n        docs: RxDocumentData<RxDocType>[],\n        checkpoint: CheckpointType\n    ): Promise<boolean> {\n        state.stats.up.persistToMaster = state.stats.up.persistToMaster + 1;\n\n        /**\n         * Add the new docs to the non-persistent list\n         */\n        docs.forEach(docData => {\n            const docId: string = (docData as any)[state.primaryPath];\n            nonPersistedFromMaster.docs[docId] = docData;\n        });\n        nonPersistedFromMaster.checkpoint = checkpoint;\n\n        persistenceQueue = persistenceQueue.then(async () => {\n            if (state.events.canceled.getValue()) {\n                return false;\n            }\n\n            const upDocsById: ById<RxDocumentData<RxDocType>> = nonPersistedFromMaster.docs;\n            nonPersistedFromMaster.docs = {};\n            const useCheckpoint = nonPersistedFromMaster.checkpoint;\n            const docIds = Object.keys(upDocsById);\n            /**\n             * Even if we do not have anything to push,\n             * we still have to store the up-checkpoint.\n             * This ensures that when many documents have been pulled\n             * from the remote (that do not have to be pushed again),\n             * we continue at the correct position and do not have to load\n             * these documents from the storage again when the replication is restarted.\n             */\n            function rememberCheckpointBeforeReturn() {\n                return setCheckpoint(\n                    state,\n                    'up',\n                    useCheckpoint\n                );\n            };\n\n\n            if (docIds.length === 0) {\n                rememberCheckpointBeforeReturn();\n                return false;\n            }\n\n            const assumedMasterState = await getAssumedMasterState(\n                state,\n                docIds\n            );\n\n            const writeRowsToMaster: ById<RxReplicationWriteToMasterRow<RxDocType>> = {};\n            const writeRowsToMasterIds: string[] = [];\n            const writeRowsToMeta: BulkWriteRowById<RxStorageReplicationMeta<RxDocType, any>> = {};\n            const forkStateById: ById<RxDocumentData<RxDocType>> = {};\n\n            await Promise.all(\n                docIds.map(async (docId) => {\n                    const fullDocData: RxDocumentData<RxDocType> = upDocsById[docId];\n                    forkStateById[docId] = fullDocData;\n                    const docData: WithDeleted<RxDocType> = writeDocToDocState(fullDocData, state.hasAttachments, !!state.input.keepMeta);\n                    const assumedMasterDoc = assumedMasterState[docId];\n\n                    /**\n                     * If the master state is equal to the\n                     * fork state, we can assume that the document state is already\n                     * replicated.\n                     */\n                    if (\n                        (\n                            assumedMasterDoc &&\n                            // if the isResolvedConflict is correct, we do not have to compare the documents.\n                            assumedMasterDoc.metaDocument.isResolvedConflict !== fullDocData._rev\n                            &&\n                            (\n                                state.input.conflictHandler.isEqual(\n                                    assumedMasterDoc.docData,\n                                    docData,\n                                    'upstream-check-if-equal'\n                                )\n                            )\n                        )\n                        ||\n                        /**\n                         * If the master works with _rev fields,\n                         * we use that to check if our current doc state\n                         * is different from the assumedMasterDoc.\n                         */\n                        (\n                            assumedMasterDoc &&\n                            (assumedMasterDoc.docData as any)._rev &&\n                            getHeightOfRevision(fullDocData._rev) === fullDocData._meta[state.input.identifier]\n                        )\n                    ) {\n                        return;\n                    }\n\n                    writeRowsToMasterIds.push(docId);\n\n                    writeRowsToMaster[docId] = {\n                        assumedMasterState: assumedMasterDoc ? assumedMasterDoc.docData : undefined,\n                        newDocumentState: docData\n                    };\n                    writeRowsToMeta[docId] = await getMetaWriteRow(\n                        state,\n                        docData,\n                        assumedMasterDoc ? assumedMasterDoc.metaDocument : undefined\n                    );\n                })\n            );\n\n            if (writeRowsToMasterIds.length === 0) {\n                rememberCheckpointBeforeReturn();\n                return false;\n            }\n\n\n            const writeRowsArray = Object.values(writeRowsToMaster);\n            const conflictIds: Set<string> = new Set();\n            const conflictsById: ById<WithDeleted<RxDocType>> = {};\n\n            /**\n             * To always respect the push.batchSize,\n             * we have to split the write rows into batches\n             * to ensure that replicationHandler.masterWrite() is never\n             * called with more documents than what the batchSize limits.\n             */\n            const writeBatches = batchArray(writeRowsArray, state.input.pushBatchSize);\n            await Promise.all(\n                writeBatches.map(async (writeBatch) => {\n\n                    // enhance docs with attachments\n                    if (state.hasAttachments) {\n                        await Promise.all(\n                            writeBatch.map(async (row) => {\n                                row.newDocumentState = await fillWriteDataForAttachmentsChange(\n                                    state.primaryPath,\n                                    state.input.forkInstance,\n                                    clone(row.newDocumentState),\n                                    row.assumedMasterState\n                                );\n                            })\n                        );\n                    }\n                    const masterWriteResult = await replicationHandler.masterWrite(writeBatch);\n                    masterWriteResult.forEach(conflictDoc => {\n                        const id = (conflictDoc as any)[state.primaryPath];\n                        conflictIds.add(id);\n                        conflictsById[id] = conflictDoc;\n                    });\n                })\n            );\n\n            const useWriteRowsToMeta: BulkWriteRow<RxStorageReplicationMeta<RxDocType, any>>[] = [];\n\n            writeRowsToMasterIds.forEach(docId => {\n                if (!conflictIds.has(docId)) {\n                    state.events.processed.up.next(writeRowsToMaster[docId]);\n                    useWriteRowsToMeta.push(writeRowsToMeta[docId]);\n                }\n            });\n\n            if (state.events.canceled.getValue()) {\n                return false;\n            }\n\n            if (useWriteRowsToMeta.length > 0) {\n                await state.input.metaInstance.bulkWrite(\n                    stripAttachmentsDataFromMetaWriteRows(state, useWriteRowsToMeta),\n                    'replication-up-write-meta'\n                );\n                // TODO what happens when we have conflicts here?\n            }\n\n            /**\n             * Resolve conflicts by writing a new document\n             * state to the fork instance and the 'real' master state\n             * to the meta instance.\n             * Non-409 errors will be detected by resolveConflictError()\n             */\n            let hadConflictWrites = false;\n            if (conflictIds.size > 0) {\n                state.stats.up.persistToMasterHadConflicts = state.stats.up.persistToMasterHadConflicts + 1;\n                const conflictWriteFork: BulkWriteRow<RxDocType>[] = [];\n                const conflictWriteMeta: BulkWriteRowById<RxStorageReplicationMeta<RxDocType, any>> = {};\n                await Promise.all(\n                    Object\n                        .entries(conflictsById)\n                        .map(([docId, realMasterState]) => {\n                            const writeToMasterRow = writeRowsToMaster[docId];\n                            const input = {\n                                newDocumentState: writeToMasterRow.newDocumentState,\n                                assumedMasterState: writeToMasterRow.assumedMasterState,\n                                realMasterState\n                            };\n                            return resolveConflictError(\n                                state,\n                                input,\n                                forkStateById[docId]\n                            ).then(async (resolved) => {\n                                if (resolved) {\n                                    state.events.resolvedConflicts.next({\n                                        input,\n                                        output: resolved\n                                    });\n                                    conflictWriteFork.push({\n                                        previous: forkStateById[docId],\n                                        document: resolved\n                                    });\n                                    const assumedMasterDoc = assumedMasterState[docId];\n                                    conflictWriteMeta[docId] = await getMetaWriteRow(\n                                        state,\n                                        ensureNotFalsy(realMasterState),\n                                        assumedMasterDoc ? assumedMasterDoc.metaDocument : undefined,\n                                        resolved._rev\n                                    );\n                                }\n                            });\n                        })\n                );\n\n                if (conflictWriteFork.length > 0) {\n                    hadConflictWrites = true;\n\n                    state.stats.up.persistToMasterConflictWrites = state.stats.up.persistToMasterConflictWrites + 1;\n                    const forkWriteResult = await state.input.forkInstance.bulkWrite(\n                        conflictWriteFork,\n                        'replication-up-write-conflict'\n                    );\n\n                    let mustThrow: RxError | undefined;\n                    forkWriteResult.error.forEach(error => {\n                        /**\n                         * Conflict-Errors in the forkWriteResult must not be handled\n                         * because they have been caused by a write to the forkInstance\n                         * in between which will anyway trigger a new upstream cycle\n                         * that will then resolved the conflict again.\n                         */\n                        if (error.status === 409) {\n                            return;\n                        }\n                        // other non-conflict errors must be handled\n                        const throwMe = newRxError('RC_PUSH', {\n                            writeError: error\n                        });\n                        state.events.error.next(throwMe);\n                        mustThrow = throwMe;\n                    });\n                    if (mustThrow) {\n                        throw mustThrow;\n                    }\n\n                    const useMetaWrites: BulkWriteRow<RxStorageReplicationMeta<RxDocType, any>>[] = [];\n                    const success = getWrittenDocumentsFromBulkWriteResponse(\n                        state.primaryPath,\n                        conflictWriteFork,\n                        forkWriteResult\n                    );\n                    success\n                        .forEach(docData => {\n                            const docId = (docData as any)[state.primaryPath];\n                            useMetaWrites.push(\n                                conflictWriteMeta[docId]\n                            );\n                        });\n                    if (useMetaWrites.length > 0) {\n                        await state.input.metaInstance.bulkWrite(\n                            stripAttachmentsDataFromMetaWriteRows(state, useMetaWrites),\n                            'replication-up-write-conflict-meta'\n                        );\n                    }\n                    // TODO what to do with conflicts while writing to the metaInstance?\n                }\n            }\n\n            /**\n             * For better performance we do not await checkpoint writes,\n             * but to ensure order on parallel checkpoint writes,\n             * we have to use a queue.\n             */\n            rememberCheckpointBeforeReturn();\n\n            return hadConflictWrites;\n        }).catch(unhandledError => {\n            state.events.error.next(unhandledError);\n            return false;\n        });\n\n        return persistenceQueue;\n    }\n}\n", "/**\n * These files contain the replication protocol.\n * It can be used to replicated RxStorageInstances or RxCollections\n * or even to do a client(s)-server replication.\n */\n\n\nimport {\n    BehaviorSubject,\n    combineLatest,\n    filter,\n    firstValueFrom,\n    mergeMap,\n    Subject\n} from 'rxjs';\nimport {\n    getPrimaryFieldOfPrimaryKey\n} from '../rx-schema-helper.ts';\nimport type {\n    BulkWriteRow,\n    ById,\n    DocumentsWithCheckpoint,\n    RxConflictHandler,\n    RxDocumentData,\n    RxReplicationHandler,\n    RxReplicationWriteToMasterRow,\n    RxStorageInstance,\n    RxStorageInstanceReplicationInput,\n    RxStorageInstanceReplicationState,\n    WithDeleted\n} from '../types/index.d.ts';\nimport {\n    clone,\n    ensureNotFalsy,\n    flatClone,\n    PROMISE_RESOLVE_VOID\n} from '../plugins/utils/index.ts';\nimport {\n    getCheckpointKey\n} from './checkpoint.ts';\nimport { startReplicationDownstream } from './downstream.ts';\nimport { docStateToWriteDoc, getUnderlyingPersistentStorage, writeDocToDocState } from './helper.ts';\nimport { startReplicationUpstream } from './upstream.ts';\nimport { fillWriteDataForAttachmentsChange } from '../plugins/attachments/index.ts';\nimport { getChangedDocumentsSince } from '../rx-storage-helper.ts';\nimport { newRxError } from '../rx-error.ts';\n\n\nexport * from './checkpoint.ts';\nexport * from './downstream.ts';\nexport * from './upstream.ts';\nexport * from './meta-instance.ts';\nexport * from './conflicts.ts';\nexport * from './helper.ts';\nexport * from './default-conflict-handler.ts';\n\n\nexport function replicateRxStorageInstance<RxDocType>(\n    input: RxStorageInstanceReplicationInput<RxDocType>\n): RxStorageInstanceReplicationState<RxDocType> {\n    input = flatClone(input);\n    input.forkInstance = getUnderlyingPersistentStorage(input.forkInstance);\n    input.metaInstance = getUnderlyingPersistentStorage(input.metaInstance);\n    const checkpointKeyPromise = getCheckpointKey(input);\n    const state: RxStorageInstanceReplicationState<RxDocType> = {\n        primaryPath: getPrimaryFieldOfPrimaryKey(input.forkInstance.schema.primaryKey),\n        hasAttachments: !!input.forkInstance.schema.attachments,\n        input,\n        checkpointKey: checkpointKeyPromise,\n        downstreamBulkWriteFlag: checkpointKeyPromise.then(checkpointKey => 'replication-downstream-' + checkpointKey),\n        events: {\n            canceled: new BehaviorSubject<boolean>(false),\n            paused: new BehaviorSubject<boolean>(false),\n            active: {\n                down: new BehaviorSubject<boolean>(true),\n                up: new BehaviorSubject<boolean>(true)\n            },\n            processed: {\n                down: new Subject(),\n                up: new Subject()\n            },\n            resolvedConflicts: new Subject(),\n            error: new Subject()\n        },\n        stats: {\n            down: {\n                addNewTask: 0,\n                downstreamProcessChanges: 0,\n                downstreamResyncOnce: 0,\n                masterChangeStreamEmit: 0,\n                persistFromMaster: 0\n            },\n            up: {\n                forkChangeStreamEmit: 0,\n                persistToMaster: 0,\n                persistToMasterConflictWrites: 0,\n                persistToMasterHadConflicts: 0,\n                processTasks: 0,\n                upstreamInitialSync: 0\n            }\n        },\n        firstSyncDone: {\n            down: new BehaviorSubject<boolean>(false),\n            up: new BehaviorSubject<boolean>(false)\n        },\n        streamQueue: {\n            down: PROMISE_RESOLVE_VOID,\n            up: PROMISE_RESOLVE_VOID\n        },\n        checkpointQueue: PROMISE_RESOLVE_VOID,\n        lastCheckpointDoc: {}\n    };\n\n    startReplicationDownstream(state);\n    startReplicationUpstream(state);\n    return state;\n}\n\nexport function awaitRxStorageReplicationFirstInSync(\n    state: RxStorageInstanceReplicationState<any>\n): Promise<void> {\n    return firstValueFrom(\n        combineLatest([\n            state.firstSyncDone.down.pipe(\n                filter(v => !!v)\n            ),\n            state.firstSyncDone.up.pipe(\n                filter(v => !!v)\n            )\n        ])\n    ).then(() => { });\n}\n\nexport function awaitRxStorageReplicationInSync(\n    replicationState: RxStorageInstanceReplicationState<any>\n) {\n    return Promise.all([\n        replicationState.streamQueue.up,\n        replicationState.streamQueue.down,\n        replicationState.checkpointQueue\n    ]);\n}\n\n\nexport async function awaitRxStorageReplicationIdle(\n    state: RxStorageInstanceReplicationState<any>\n) {\n    await awaitRxStorageReplicationFirstInSync(state);\n    while (true) {\n        const { down, up } = state.streamQueue;\n        await Promise.all([\n            up,\n            down\n        ]);\n        /**\n         * If the Promises have not been reassigned\n         * after awaiting them, we know that the replication\n         * is in idle state at this point in time.\n         */\n        if (\n            down === state.streamQueue.down &&\n            up === state.streamQueue.up\n        ) {\n            return;\n        }\n    }\n}\n\n\nexport function rxStorageInstanceToReplicationHandler<RxDocType, MasterCheckpointType>(\n    instance: RxStorageInstance<RxDocType, any, any, MasterCheckpointType>,\n    conflictHandler: RxConflictHandler<RxDocType>,\n    databaseInstanceToken: string,\n    /**\n     * If set to true,\n     * the _meta.lwt from the pushed documents is kept.\n     * (Used in the migration to ensure checkpoints are still valid)\n     */\n    keepMeta: boolean = false\n): RxReplicationHandler<RxDocType, MasterCheckpointType> {\n    instance = getUnderlyingPersistentStorage(instance);\n\n    const hasAttachments = !!instance.schema.attachments;\n    const primaryPath = getPrimaryFieldOfPrimaryKey(instance.schema.primaryKey);\n    const replicationHandler: RxReplicationHandler<RxDocType, MasterCheckpointType> = {\n        masterChangeStream$: instance.changeStream().pipe(\n            mergeMap(async (eventBulk) => {\n                const ret: DocumentsWithCheckpoint<RxDocType, MasterCheckpointType> = {\n                    checkpoint: eventBulk.checkpoint,\n                    documents: await Promise.all(\n                        eventBulk.events.map(async (event) => {\n                            let docData = writeDocToDocState(event.documentData, hasAttachments, keepMeta);\n                            if (hasAttachments) {\n                                docData = await fillWriteDataForAttachmentsChange(\n                                    primaryPath,\n                                    instance,\n                                    clone(docData),\n                                    /**\n                                     * Notice that the master never knows\n                                     * the client state of the document.\n                                     * Therefore we always send all attachments data.\n                                     */\n                                    undefined\n                                );\n                            }\n                            return docData;\n                        })\n                    )\n                };\n                return ret;\n            })\n        ),\n        masterChangesSince(\n            checkpoint,\n            batchSize\n        ) {\n            return getChangedDocumentsSince(\n                instance,\n                batchSize,\n                checkpoint\n            ).then(async (result) => {\n                return {\n                    checkpoint: result.documents.length > 0 ? result.checkpoint : checkpoint,\n                    documents: await Promise.all(\n                        result.documents.map(async (plainDocumentData) => {\n                            let docData = writeDocToDocState(plainDocumentData, hasAttachments, keepMeta);\n                            if (hasAttachments) {\n                                docData = await fillWriteDataForAttachmentsChange(\n                                    primaryPath,\n                                    instance,\n                                    clone(docData),\n                                    /**\n                                     * Notice the the master never knows\n                                     * the client state of the document.\n                                     * Therefore we always send all attachments data.\n                                     */\n                                    undefined\n                                );\n                            }\n                            return docData;\n                        })\n                    )\n                };\n            });\n        },\n        async masterWrite(\n            rows\n        ) {\n            const rowById: ById<RxReplicationWriteToMasterRow<RxDocType>> = {};\n            rows.forEach(row => {\n                const docId: string = (row.newDocumentState as any)[primaryPath];\n                rowById[docId] = row;\n            });\n            const ids = Object.keys(rowById);\n\n            const masterDocsStateList = await instance.findDocumentsById(\n                ids,\n                true\n            );\n            const masterDocsState = new Map<string, RxDocumentData<RxDocType>>();\n            masterDocsStateList.forEach(doc => masterDocsState.set((doc as any)[primaryPath], doc));\n            const conflicts: WithDeleted<RxDocType>[] = [];\n            const writeRows: BulkWriteRow<RxDocType>[] = [];\n            await Promise.all(\n                Object.entries(rowById)\n                    .map(([id, row]) => {\n                        const masterState = masterDocsState.get(id);\n                        if (!masterState) {\n                            writeRows.push({\n                                document: docStateToWriteDoc(databaseInstanceToken, hasAttachments, keepMeta, row.newDocumentState)\n                            });\n                        } else if (\n                            masterState &&\n                            !row.assumedMasterState\n                        ) {\n                            conflicts.push(writeDocToDocState(masterState, hasAttachments, keepMeta));\n                        } else if (\n                            conflictHandler.isEqual(\n                                writeDocToDocState(masterState, hasAttachments, keepMeta),\n                                ensureNotFalsy(row.assumedMasterState),\n                                'rxStorageInstanceToReplicationHandler-masterWrite'\n                            ) === true\n                        ) {\n                            writeRows.push({\n                                previous: masterState,\n                                document: docStateToWriteDoc(databaseInstanceToken, hasAttachments, keepMeta, row.newDocumentState, masterState)\n                            });\n                        } else {\n                            conflicts.push(writeDocToDocState(masterState, hasAttachments, keepMeta));\n                        }\n                    })\n            );\n\n            if (writeRows.length > 0) {\n                const result = await instance.bulkWrite(\n                    writeRows,\n                    'replication-master-write'\n                );\n\n                result.error.forEach(err => {\n                    if (err.status !== 409) {\n                        throw newRxError('SNH', {\n                            name: 'non conflict error',\n                            error: err as any\n                        });\n                    } else {\n                        conflicts.push(\n                            writeDocToDocState(ensureNotFalsy(err.documentInDb), hasAttachments, keepMeta)\n                        );\n                    }\n                });\n            }\n            return conflicts;\n        }\n    };\n\n    return replicationHandler;\n}\n\n\nexport async function cancelRxStorageReplication(\n    replicationState: RxStorageInstanceReplicationState<any>\n) {\n    replicationState.events.canceled.next(true);\n    replicationState.events.active.up.complete();\n    replicationState.events.active.down.complete();\n    replicationState.events.processed.up.complete();\n    replicationState.events.processed.down.complete();\n    replicationState.events.resolvedConflicts.complete();\n    replicationState.events.canceled.complete();\n    await replicationState.checkpointQueue;\n}\n", "/**\n * For some RxStorage implementations,\n * we need to use our custom crafted indexes\n * so we can easily iterate over them. And sort plain arrays of document data.\n *\n * We really often have to craft an index string for a given document.\n * Performance of everything in this file is very important\n * which is why the code sometimes looks strange.\n * Run performance tests before and after you touch anything here!\n */\n\nimport {\n    getSchemaByObjectPath\n} from './rx-schema-helper.ts';\nimport type {\n    JsonSchema,\n    RxDocumentData,\n    RxJsonSchema\n} from './types/index.ts';\nimport {\n    ensureNotFalsy,\n    objectPathMonad,\n    ObjectPathMonadFunction\n} from './plugins/utils/index.ts';\nimport {\n    INDEX_MAX,\n    INDEX_MIN\n} from './query-planner.ts';\n\n\n/**\n * Prepare all relevant information\n * outside of the returned function\n * from getIndexableStringMonad()\n * to save performance when the returned\n * function is called many times.\n */\ntype IndexMetaField<RxDocType> = {\n    fieldName: string;\n    schemaPart: JsonSchema;\n    /*\n     * Only in number fields.\n     */\n    parsedLengths?: ParsedLengths;\n    getValue: ObjectPathMonadFunction<RxDocType>;\n    getIndexStringPart: (docData: RxDocumentData<RxDocType>) => string;\n};\n\nexport function getIndexMeta<RxDocType>(\n    schema: RxJsonSchema<RxDocumentData<RxDocType>>,\n    index: string[]\n): IndexMetaField<RxDocType>[] {\n    const fieldNameProperties: IndexMetaField<RxDocType>[] = index.map(fieldName => {\n        const schemaPart = getSchemaByObjectPath(\n            schema,\n            fieldName\n        );\n        if (!schemaPart) {\n            throw new Error('not in schema: ' + fieldName);\n        }\n        const type = schemaPart.type;\n        let parsedLengths: ParsedLengths | undefined;\n        if (type === 'number' || type === 'integer') {\n            parsedLengths = getStringLengthOfIndexNumber(\n                schemaPart\n            );\n        }\n\n        const getValue = objectPathMonad(fieldName);\n        const maxLength = schemaPart.maxLength ? schemaPart.maxLength : 0;\n\n        let getIndexStringPart: (docData: RxDocumentData<RxDocType>) => string;\n        if (type === 'string') {\n            getIndexStringPart = docData => {\n                let fieldValue = getValue(docData);\n                if (!fieldValue) {\n                    fieldValue = '';\n                }\n                return fieldValue.padEnd(maxLength, ' ');\n            };\n        } else if (type === 'boolean') {\n            getIndexStringPart = docData => {\n                const fieldValue = getValue(docData);\n                return fieldValue ? '1' : '0';\n            };\n        } else { // number\n            getIndexStringPart = docData => {\n                const fieldValue = getValue(docData);\n                return getNumberIndexString(\n                    parsedLengths as any,\n                    fieldValue\n                );\n            };\n        }\n\n        const ret: IndexMetaField<RxDocType> = {\n            fieldName,\n            schemaPart,\n            parsedLengths,\n            getValue,\n            getIndexStringPart\n        };\n        return ret;\n    });\n    return fieldNameProperties;\n}\n\n\n/**\n * Crafts an indexable string that can be used\n * to check if a document would be sorted below or above\n * another documents, dependent on the index values.\n * @monad for better performance\n *\n * IMPORTANT: Performance is really important here\n * which is why we code so 'strange'.\n * Always run performance tests when you want to\n * change something in this method.\n */\nexport function getIndexableStringMonad<RxDocType>(\n    schema: RxJsonSchema<RxDocumentData<RxDocType>>,\n    index: string[]\n): (docData: RxDocumentData<RxDocType>) => string {\n    const fieldNameProperties = getIndexMeta(schema, index);\n    const fieldNamePropertiesAmount = fieldNameProperties.length;\n    const indexPartsFunctions = fieldNameProperties.map(r => r.getIndexStringPart);\n\n\n    /**\n     * @hotPath Performance of this function is very critical!\n     */\n    const ret = function (docData: RxDocumentData<RxDocType>): string {\n        let str = '';\n        for (let i = 0; i < fieldNamePropertiesAmount; ++i) {\n            str += indexPartsFunctions[i](docData);\n        }\n        return str;\n    };\n    return ret;\n}\n\n\ndeclare type ParsedLengths = {\n    minimum: number;\n    maximum: number;\n    nonDecimals: number;\n    decimals: number;\n    roundedMinimum: number;\n};\nexport function getStringLengthOfIndexNumber(\n    schemaPart: JsonSchema\n): ParsedLengths {\n    const minimum = Math.floor(schemaPart.minimum as number);\n    const maximum = Math.ceil(schemaPart.maximum as number);\n    const multipleOf: number = schemaPart.multipleOf as number;\n\n    const valueSpan = maximum - minimum;\n    const nonDecimals = valueSpan.toString().length;\n\n    const multipleOfParts = multipleOf.toString().split('.');\n    let decimals = 0;\n    if (multipleOfParts.length > 1) {\n        decimals = multipleOfParts[1].length;\n    }\n    return {\n        minimum,\n        maximum,\n        nonDecimals,\n        decimals,\n        roundedMinimum: minimum\n    };\n}\n\nexport function getIndexStringLength<RxDocType>(\n    schema: RxJsonSchema<RxDocumentData<RxDocType>>,\n    index: string[]\n): number {\n    const fieldNameProperties = getIndexMeta(schema, index);\n    let length = 0;\n    fieldNameProperties.forEach(props => {\n        const schemaPart = props.schemaPart;\n        const type = schemaPart.type;\n\n        if (type === 'string') {\n            length += schemaPart.maxLength as number;\n        } else if (type === 'boolean') {\n            length += 1;\n        } else {\n            const parsedLengths = props.parsedLengths as ParsedLengths;\n            length = length + parsedLengths.nonDecimals + parsedLengths.decimals;\n        }\n\n    });\n    return length;\n}\n\n\nexport function getPrimaryKeyFromIndexableString(\n    indexableString: string,\n    primaryKeyLength: number\n): string {\n    const paddedPrimaryKey = indexableString.slice(primaryKeyLength * -1);\n    // we can safely trim here because the primary key is not allowed to start or end with a space char.\n    const primaryKey = paddedPrimaryKey.trim();\n    return primaryKey;\n}\n\n\nexport function getNumberIndexString(\n    parsedLengths: ParsedLengths,\n    fieldValue: number\n): string {\n    /**\n     * Ensure that the given value is in the boundaries\n     * of the schema, otherwise it would create a broken index string.\n     * This can happen for example if you have a minimum of 0\n     * and run a query like\n     * selector {\n     *  numField: { $gt: -1000 }\n     * }\n     */\n    if (typeof fieldValue === 'undefined') {\n        fieldValue = 0;\n    }\n    if (fieldValue < parsedLengths.minimum) {\n        fieldValue = parsedLengths.minimum;\n    }\n    if (fieldValue > parsedLengths.maximum) {\n        fieldValue = parsedLengths.maximum;\n    }\n\n    const nonDecimalsValueAsString = (Math.floor(fieldValue) - parsedLengths.roundedMinimum).toString();\n    let str = nonDecimalsValueAsString.padStart(parsedLengths.nonDecimals, '0');\n\n    if (parsedLengths.decimals > 0) {\n        const splitByDecimalPoint = fieldValue.toString().split('.');\n        const decimalValueAsString = splitByDecimalPoint.length > 1 ? splitByDecimalPoint[1] : '0';\n        str += decimalValueAsString.padEnd(parsedLengths.decimals, '0');\n    }\n    return str;\n}\n\nexport function getStartIndexStringFromLowerBound(\n    schema: RxJsonSchema<any>,\n    index: string[],\n    lowerBound: (string | boolean | number | null | undefined)[]\n): string {\n    let str = '';\n    index.forEach((fieldName, idx) => {\n        const schemaPart = getSchemaByObjectPath(\n            schema,\n            fieldName\n        );\n        const bound = lowerBound[idx];\n        const type = schemaPart.type;\n\n        switch (type) {\n            case 'string':\n                const maxLength = ensureNotFalsy(schemaPart.maxLength, 'maxLength not set');\n                if (typeof bound === 'string') {\n                    str += (bound as string).padEnd(maxLength, ' ');\n                } else {\n                    // str += ''.padStart(maxLength, inclusiveStart ? ' ' : INDEX_MAX);\n                    str += ''.padEnd(maxLength, ' ');\n                }\n                break;\n            case 'boolean':\n                if (bound === null) {\n                    str += '0';\n                } else if (bound === INDEX_MIN) {\n                    str += '0';\n                } else if (bound === INDEX_MAX) {\n                    str += '1';\n                } else {\n                    const boolToStr = bound ? '1' : '0';\n                    str += boolToStr;\n                }\n                break;\n            case 'number':\n            case 'integer':\n                const parsedLengths = getStringLengthOfIndexNumber(\n                    schemaPart\n                );\n                if (bound === null || bound === INDEX_MIN) {\n                    const fillChar = '0';\n                    str += fillChar.repeat(parsedLengths.nonDecimals + parsedLengths.decimals);\n                } else if (bound === INDEX_MAX) {\n                    str += getNumberIndexString(\n                        parsedLengths,\n                        parsedLengths.maximum\n                    );\n                } else {\n                    const add = getNumberIndexString(\n                        parsedLengths,\n                        bound as number\n                    );\n                    str += add;\n                }\n                break;\n            default:\n                throw new Error('unknown index type ' + type);\n        }\n    });\n    return str;\n}\n\n\nexport function getStartIndexStringFromUpperBound(\n    schema: RxJsonSchema<any>,\n    index: string[],\n    upperBound: (string | boolean | number | null | undefined)[]\n): string {\n    let str = '';\n    index.forEach((fieldName, idx) => {\n        const schemaPart = getSchemaByObjectPath(\n            schema,\n            fieldName\n        );\n        const bound = upperBound[idx];\n        const type = schemaPart.type;\n\n        switch (type) {\n            case 'string':\n                const maxLength = ensureNotFalsy(schemaPart.maxLength, 'maxLength not set');\n                if (typeof bound === 'string' && bound !== INDEX_MAX) {\n                    str += (bound as string).padEnd(maxLength, ' ');\n                } else if (bound === INDEX_MIN) {\n                    str += ''.padEnd(maxLength, ' ');\n                } else {\n                    str += ''.padEnd(maxLength, INDEX_MAX);\n                }\n                break;\n            case 'boolean':\n                if (bound === null) {\n                    str += '1';\n                } else {\n                    const boolToStr = bound ? '1' : '0';\n                    str += boolToStr;\n                }\n                break;\n            case 'number':\n            case 'integer':\n                const parsedLengths = getStringLengthOfIndexNumber(\n                    schemaPart\n                );\n                if (bound === null || bound === INDEX_MAX) {\n                    const fillChar = '9';\n                    str += fillChar.repeat(parsedLengths.nonDecimals + parsedLengths.decimals);\n                } else if (bound === INDEX_MIN) {\n                    const fillChar = '0';\n                    str += fillChar.repeat(parsedLengths.nonDecimals + parsedLengths.decimals);\n                } else {\n                    str += getNumberIndexString(\n                        parsedLengths,\n                        bound as number\n                    );\n                }\n                break;\n            default:\n                throw new Error('unknown index type ' + type);\n        }\n    });\n    return str;\n}\n\n/**\n * Used in storages where it is not possible\n * to define inclusiveEnd/inclusiveStart\n */\nexport function changeIndexableStringByOneQuantum(str: string, direction: 1 | -1): string {\n    const lastChar = str.slice(-1);\n    let charCode = lastChar.charCodeAt(0);\n    charCode = charCode + direction;\n    const withoutLastChar = str.slice(0, -1);\n    return withoutLastChar + String.fromCharCode(charCode);\n}\n"],
  "mappings": ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAkCA,IAAMA,aAAoC;EACtCC,UAAUA,SAASC;EACnBC,YAAYC;EACZC,SAASC,YAAYJ;EACrBK,cAAcC,iBAAiBN;EAC/BO,YAAYC,eAAeR;AAC/B;AAEA,IAAMS,gBAAqC,oBAAIC,IAAI;AACnD,IAAMC,qBAAkC,oBAAID,IAAI;AAMzC,SAASE,YAAYC,QAAkB;AAC1CC,iBAAe,kBAAkB;IAAED;IAAQE,SAASN;EAAc,CAAC;AAGnE,MAAIA,cAAcO,IAAIH,MAAM,GAAG;AAC3B;EACJ,OAAO;AAGH,QAAIF,mBAAmBK,IAAIH,OAAOI,IAAI,GAAG;AACrC,YAAMC,WAAW,OAAO;QACpBD,MAAMJ,OAAOI;QACbJ;MACJ,CAAC;IACL;AAEAJ,kBAAcU,IAAIN,MAAM;AACxBF,uBAAmBQ,IAAIN,OAAOI,IAAI;EACtC;AAMA,MAAI,CAACJ,OAAOO,MAAM;AACd,UAAMC,eAAe,OAAO;MACxBR;IACJ,CAAC;EACL;AAEA,MAAIA,OAAOS,MAAM;AACbT,WAAOS,KAAK;EAChB;AAGA,MAAIT,OAAOU,YAAY;AACnBC,WACKC,QAAQZ,OAAOU,UAAU,EACzBG,QAAQ,CAAC,CAACT,MAAMU,GAAG,MAAM;AACtB,aAAQA,IAAY7B,WAAWmB,IAAI,CAAC;IACxC,CAAC;EACT;AAEA,MAAIJ,OAAOe,cAAc;AACrBJ,WAAOK,OACHD,cACAf,OAAOe,YACX;EACJ;AAEA,MAAIf,OAAOiB,OAAO;AACdN,WACKC,QAAQZ,OAAOiB,KAAK,EACpBJ,QAAQ,CAAC,CAACT,MAAMc,QAAQ,MAAM;AAC3B,UAAIA,SAASC,OAAO;AACfC,cAAchB,IAAI,EAAEiB,KAAKH,SAASC,KAAK;MAC5C;AACA,UAAID,SAASI,QAAQ;AAChBF,cAAchB,IAAI,EAAEmB,QAAQL,SAASI,MAAM;MAChD;IACJ,CAAC;EACT;AACJ;;;AC9FA,eAAsBE,qBAClBC,OACAC,WACmC;AACnC,MAAMC,kBAAkBC,oCACpBH,MAAMI,MAAMC,aAAaC,QACzB;IACIC,cAAc;IACdC,QAAQP;EACZ,CACJ;AACA,MAAMQ,mBAAmB,MAAMT,MAAMI,MAAMC,aAAaK,kBACpD,CACIR,eAAe,GAEnB,KACJ;AAEA,MAAMS,gBAAgBF,iBAAiB,CAAC;AACxCT,QAAMY,kBAAkBX,SAAS,IAAIU;AACrC,MAAIA,eAAe;AACf,WAAOA,cAAcE;EACzB,OAAO;AACH,WAAOC;EACX;AACJ;AAOA,eAAsBC,cAClBf,OACAC,WACAe,YACF;AACEhB,QAAMiB,kBAAkBjB,MAAMiB,gBAAgBC,KAAK,YAAY;AAC3D,QAAIC,wBAAwBnB,MAAMY,kBAAkBX,SAAS;AAC7D,QACIe;;;;;;;IAQA,CAAChB,MAAMoB,OAAOC,SAASC,SAAS;;;;KAM5B,CAACH,yBACDI,KAAKC,UAAUL,sBAAsBN,cAAc,MAAMU,KAAKC,UAAUR,UAAU,IAExF;AACE,UAAMS,SAA8E;QAChFC,IAAI;QACJnB,cAAc;QACdC,QAAQP;QACR0B,UAAU;QACVC,cAAc,CAAC;QACff,gBAAgBG;QAChBa,OAAOC,yBAAyB;QAChCC,MAAMC,mBAAmB;MAC7B;AACAP,aAAOC,KAAKvB,oCACRH,MAAMI,MAAMC,aAAaC,QACzBmB,MACJ;AACA,aAAO,CAACzB,MAAMoB,OAAOC,SAASC,SAAS,GAAG;AAQtC,YAAIH,uBAAuB;AACvBM,iBAAOZ,iBAAiBoB,iBAAiB,CACrCd,sBAAsBN,gBACtBY,OAAOZ,cAAc,CACxB;QACL;AACAY,eAAOI,MAAMK,MAAMC,IAAI;AACvBV,eAAOM,OAAOK,eACV,MAAMpC,MAAMqC,eACZlB,qBACJ;AAEA,YAAInB,MAAMoB,OAAOC,SAASC,SAAS,GAAG;AAClC;QACJ;AAEA,YAAMgB,YAAY,CAAC;UACfC,UAAUpB;UACVqB,UAAUf;QACd,CAAC;AACD,YAAMgB,SAAS,MAAMzC,MAAMI,MAAMC,aAAaqC,UAAUJ,WAAW,4BAA4B;AAC/F,YAAMK,aAAaC,yCACf5C,MAAM6C,aACNP,WACAG,MACJ,EAAE,CAAC;AACH,YAAIE,YAAY;AACZ3C,gBAAMY,kBAAkBX,SAAS,IAAI0C;AACrC;QACJ,OAAO;AACH,cAAMG,QAAQL,OAAOK,MAAM,CAAC;AAC5B,cAAIA,MAAMC,WAAW,KAAK;AACtB,kBAAMD;UACV,OAAO;AACH3B,oCAAwB6B,eAAeF,MAAMG,YAAY;AACzDxB,mBAAOM,OAAOK,eACV,MAAMpC,MAAMqC,eACZlB,qBACJ;UACJ;QACJ;MACJ;IACJ;EACJ,CAAC;AACD,QAAMnB,MAAMiB;AAChB;AAEA,eAAsBiC,iBAClB9C,OACe;AACf,MAAM+C,OAAO,MAAM/C,MAAMgD,aAAa,CAClChD,MAAMiD,YACNjD,MAAMkD,aAAaC,cACnBnD,MAAMkD,aAAaE,cAAc,EACnCC,KAAK,IAAI,CAAC;AACZ,SAAO,4BAA4BN;AACvC;;;ACvIO,SAASO,mBACZC,uBACAC,gBACAC,UACAC,UACAC,UAC8B;AAC9B,MAAMC,UAA0CC,OAAOC,OACnD,CAAC,GACDJ,UACA;IACIK,cAAcP,kBAAkBE,SAASK,eAAeL,SAASK,eAAe,CAAC;IACjFC,OAAOP,WAAYC,SAAiBM,QAAQH,OAAOC,OAC/C,CAAC,GACDH,WAAWA,SAASK,QAAQ,CAAC,GAC7B;MACIC,KAAKC,IAAI;IACb,CACJ;IACAC,MAAMV,WAAYC,SAAiBS,OAAOC,mBAAmB;EACjE,CACJ;AACA,MAAI,CAACR,QAAQO,MAAM;AACfP,YAAQO,OAAOE,eACXd,uBACAI,QACJ;EACJ;AAEA,SAAOC;AACX;AAEO,SAASU,mBACZC,UACAC,iBACAf,UACoC;AACpC,MAAMgB,MAAMC,UAAUH,QAAQ;AAE9B,MAAI,CAACC,iBAAiB;AAClB,WAAQC,IAAYV;EACxB;AACA,MAAI,CAACN,UAAU;AACX,WAAQgB,IAAYT;AACpB,WAAQS,IAAYN;EACxB;AACA,SAAOM;AACX;AAGO,SAASE,sCACZC,OACAC,MACwD;AACxD,MAAI,CAACD,MAAMpB,gBAAgB;AACvB,WAAOqB;EACX;AACA,SAAOA,KAAKC,IAAIC,SAAO;AACnB,QAAMC,WAAWC,MAAMF,IAAIC,QAAQ;AACnCA,aAASpB,UAAUsB,iCAAiCF,SAASpB,OAAO;AACpE,WAAO;MACHoB;MACArB,UAAUoB,IAAIpB;IAClB;EACJ,CAAC;AACL;AAEO,SAASwB,+BACZC,UAC2C;AAC3C,SAAO,MAAM;AACT,QAAIA,SAASC,6BAA6B;AACtCD,iBAAWA,SAASC;IACxB,OAAO;AACH,aAAOD;IACX;EACJ;AACJ;;;ACzEO,IAAME,6BAA6B;AAEnC,SAASC,mCACZC,2BACAC,WACiF;AACjF,MAAMC,yBAAyBC,sBAAsBH,yBAAyB;AAE9E,MAAMI,aAAgF;IAClFC,OAAOP;IACPQ,YAAY;MACRC,KAAK;MACLC,QAAQ,CACJ,UACA,cAAc;MAElBC,WAAW;IACf;IACAC,MAAM;IACNC,SAASX,0BAA0BW;IACnCC,sBAAsB;IACtBC,YAAY;MACRC,IAAI;QACAJ,MAAM;QACNK,WAAW;;QAEXC,WAAWd,yBAAyB;MACxC;MACAe,cAAc;QACVP,MAAM;QACNQ,MAAM,CACF,KACA,GAAG;QAEPH,WAAW;QACXC,WAAW;MACf;MACAG,QAAQ;QACJT,MAAM;;;;;QAKNM,WAAWd,yBAAyB,IAAIA,yBAAyB;MACrE;MACAkB,gBAAgB;QACZV,MAAM;QACNE,sBAAsB;MAC1B;MACAS,SAAS;QACLX,MAAM;QACNG,YAAYb,0BAA0Ba;MAC1C;MACAS,oBAAoB;QAChBZ,MAAM;MACV;IACJ;IACAa,gBAAgBvB,0BAA0BuB;IAC1CC,UAAU,CACN,MACA,gBACA,QAAQ;EAEhB;AACA,MAAIvB,WAAW;AACXG,eAAWH,YAAY,CAAC,SAAS;EACrC;AACA,MAAMwB,qBAAwGC,wBAAwBtB,UAAU;AAChJ,SAAOqB;AACX;AAQO,SAASE,sBACZC,OACAC,QAIA;AACA,SAAOD,MAAME,MAAMC,aAAaC,kBAC5BH,OAAOI,IAAIC,WAAS;AAChB,QAAMC,QAAQC,oCACVR,MAAME,MAAMC,aAAaM,QACzB;MACIlB,QAAQe;MACRjB,cAAc;IAClB,CACJ;AACA,WAAOkB;EACX,CAAC,GACD,IACJ,EAAEG,KAAKC,cAAY;AACf,QAAMC,MAKF,CAAC;AACLC,WACKC,OAAOH,QAAQ,EACfI,QAASC,aAAY;AAClBJ,UAAII,QAAQzB,MAAM,IAAI;QAClBE,SAASuB,QAAQvB;QACjBwB,cAAcD;MAClB;IACJ,CAAC;AAEL,WAAOJ;EACX,CAAC;AACL;AAGA,eAAsBM,gBAClBlB,OACAmB,mBACAC,UACA1B,oBAC+D;AAC/D,MAAMY,QAAiBa,kBAA0BnB,MAAMqB,WAAW;AAClE,MAAMC,UAAoEF,WAAWG,qBACjFH,QACJ,IAAI;IACAlC,IAAI;IACJG,cAAc;IACdE,QAAQe;IACRb,SAAS0B;IACTK,cAAc,CAAC;IACfC,UAAU;IACVC,MAAMC,mBAAmB;IACzBC,OAAO;MACHC,KAAK;IACT;EACJ;AACAP,UAAQ7B,UAAU0B;AAOlB,MAAIzB,oBAAoB;AACpB4B,YAAQ5B,qBAAqBA;EACjC;AAEA4B,UAAQM,MAAMC,MAAMC,IAAI;AACxBR,UAAQpC,KAAKsB,oCACTR,MAAME,MAAMC,aAAaM,QACzBa,OACJ;AACAA,UAAQI,OAAOK,eACX,MAAM/B,MAAMgC,eACZZ,QACJ;AAEA,MAAMR,MAAM;IACRQ;IACAa,UAAUX;EACd;AAEA,SAAOV;AACX;;;ACzIA,eAAsBsB,2BAClBC,OACF;AACE,MACIA,MAAMC,MAAMC,qBACZF,MAAMC,MAAMC,kBAAkBC,YAChC;AACE,QAAMC,gBAAgB,MAAMC,qBAAqBL,OAAO,MAAM;AAC9D,QAAI,CAACI,eAAe;AAChB,YAAME,cACFN,OACA,QACAA,MAAMC,MAAMC,kBAAkBC,UAClC;IACJ;EACJ;AAEA,MAAMI,iBAAiB,MAAMP,MAAMC,MAAMO,aAAaR,MAAMC,MAAMQ,UAAU;AAC5E,MAAMC,qBAAqBV,MAAMC,MAAMS;AAGvC,MAAIC,QAAQ;AAQZ,MAAMC,YAA4B,CAAA;AAGlC,WAASC,WAAWC,MAAkB;AAClCd,UAAMe,MAAMC,KAAKH,aAAab,MAAMe,MAAMC,KAAKH,aAAa;AAC5D,QAAMI,eAAe;MACjBC,MAAMP;MACNG;IACJ;AACAF,cAAUO,KAAKF,YAAY;AAC3BjB,UAAMoB,YAAYJ,OAAOhB,MAAMoB,YAAYJ,KACtCK,KAAK,MAAM;AACR,UAAMC,WAAmB,CAAA;AACzB,aAAOV,UAAUW,SAAS,GAAG;AACzBvB,cAAMwB,OAAOC,OAAOT,KAAKU,KAAK,IAAI;AAClC,YAAMC,oBAAoBC,eAAehB,UAAUiB,MAAM,CAAC;AAM1D,YAAIF,kBAAkBT,OAAOY,gCAAgC;AACzD;QACJ;AAEA,YAAIH,kBAAkBb,SAAS,UAAU;AACrC,cAAIQ,SAASC,WAAW,GAAG;AACvBD,qBAASH,KAAKQ,kBAAkBb,IAAI;AACpC;UACJ,OAAO;AACH;UACJ;QACJ;AAEAQ,iBAASH,KAAKQ,kBAAkBb,IAAI;MACxC;AACA,UAAIQ,SAASC,WAAW,GAAG;AACvB;MACJ;AAEA,UAAID,SAAS,CAAC,MAAM,UAAU;AAC1B,eAAOS,qBAAqB;MAChC,OAAO;AACH,eAAOC,yBAAyBV,QAAQ;MAC5C;IACJ,CAAC,EAAED,KAAK,MAAM;AACVrB,YAAMwB,OAAOC,OAAOT,KAAKU,KAAK,KAAK;AACnC,UACI,CAAC1B,MAAMiC,cAAcjB,KAAKkB,SAAS,KACnC,CAAClC,MAAMwB,OAAOW,SAASD,SAAS,GAClC;AACElC,cAAMiC,cAAcjB,KAAKU,KAAK,IAAI;MACtC;IACJ,CAAC;EACT;AACAb,aAAW,QAAQ;AAOnB,MAAI,CAACb,MAAMwB,OAAOW,SAASD,SAAS,GAAG;AACnC,QAAME,MAAM1B,mBACP2B,oBACAC,KACGC,SAAS,OAAOC,OAAO;AAKnB,YAAMC,eACFzC,MAAMwB,OAAOC,OAAOiB,GAAGJ,KAAKK,OAAOC,OAAK,CAACA,CAAC,CAAC,CAC/C;AACA,aAAOJ;IACX,CAAC,CACL,EACCK,UAAW/B,UAAe;AACvBd,YAAMe,MAAMC,KAAK8B,yBAAyB9C,MAAMe,MAAMC,KAAK8B,yBAAyB;AACpFjC,iBAAWC,IAAI;IACnB,CAAC;AAEL2B,mBACIzC,MAAMwB,OAAOW,SAASG,KAClBK,OAAOR,cAAY,CAAC,CAACA,QAAQ,CACjC,CACJ,EAAEd,KAAK,MAAMe,IAAIW,YAAY,CAAC;EAClC;AAOA,MAAIjB,iCAAyC;AAC7C,iBAAeC,uBAAuB;AAClC/B,UAAMe,MAAMC,KAAKe,uBAAuB/B,MAAMe,MAAMC,KAAKe,uBAAuB;AAChF,QAAI/B,MAAMwB,OAAOW,SAASD,SAAS,GAAG;AAClC;IACJ;AAEAlC,UAAMgD,kBAAkBhD,MAAMgD,gBAAgB3B,KAAK,MAAMhB,qBAAqBL,OAAO,MAAM,CAAC;AAC5F,QAAIiD,iBAAiC,MAAMjD,MAAMgD;AAGjD,QAAME,WAA2B,CAAA;AACjC,WAAO,CAAClD,MAAMwB,OAAOW,SAASD,SAAS,GAAG;AACtCJ,uCAAiCnB;AACjC,UAAMwC,aAAa,MAAMzC,mBAAmB0C,mBACxCH,gBACAjD,MAAMC,MAAMoD,aAChB;AAEA,UAAIF,WAAWG,UAAU/B,WAAW,GAAG;AACnC;MACJ;AAEA0B,uBAAiBM,iBAAiB,CAACN,gBAAgBE,WAAWK,UAAU,CAAC;AAEzEN,eAAS/B,KACLsC,kBACIN,WAAWG,WACXL,cACJ,CACJ;AAOA,UAAIE,WAAWG,UAAU/B,SAASvB,MAAMC,MAAMoD,eAAe;AACzD;MACJ;IAEJ;AACA,UAAMK,QAAQC,IAAIT,QAAQ;EAC9B;AAGA,WAASlB,yBAAyB4B,OAAe;AAC7C5D,UAAMe,MAAMC,KAAKgB,2BAA2BhC,MAAMe,MAAMC,KAAKgB,2BAA2B;AACxF,QAAM6B,iBAA2C,CAAA;AACjD,QAAIZ,iBAA6C;AAEjDW,UAAME,QAAQhD,UAAQ;AAClB,UAAIA,SAAS,UAAU;AACnB,cAAM,IAAIiD,MAAM,KAAK;MACzB;AACAC,oBAAcH,gBAAgB/C,KAAKwC,SAAS;AAC5CL,uBAAiBM,iBAAiB,CAACN,gBAAgBnC,KAAK0C,UAAU,CAAC;IACvE,CAAC;AACD,WAAOC,kBACHI,gBACAjC,eAAeqB,cAAc,CACjC;EACJ;AAWA,MAAIgB,mBAAmBC;AACvB,MAAMC,yBAGF;IACAC,MAAM,CAAC;EACX;AAEA,WAASX,kBACLW,MACAZ,YACa;AACb,QAAMa,cAAcrE,MAAMqE;AAC1BrE,UAAMe,MAAMC,KAAKyC,oBAAoBzD,MAAMe,MAAMC,KAAKyC,oBAAoB;AAK1EW,SAAKN,QAAQQ,aAAW;AACpB,UAAMC,QAAiBD,QAAgBD,WAAW;AAClDF,6BAAuBC,KAAKG,KAAK,IAAID;IACzC,CAAC;AACDH,2BAAuBX,aAAaA;AAMpCS,uBAAmBA,iBAAiB5C,KAAK,MAAM;AAC3C,UAAMmD,eAA2DL,uBAAuBC;AACxFD,6BAAuBC,OAAO,CAAC;AAC/B,UAAMK,gBAAgBN,uBAAuBX;AAC7C,UAAMkB,SAASC,OAAOC,KAAKJ,YAAY;AAEvC,UACIxE,MAAMwB,OAAOW,SAASD,SAAS,KAC/BwC,OAAOnD,WAAW,GACpB;AACE,eAAO2C;MACX;AAEA,UAAMW,kBAA6C,CAAA;AACnD,UAAMC,sBAAqD,CAAC;AAC5D,UAAMC,kBAAyF,CAAC;AAChG,UAAMC,mBAAwF,CAAA;AAE9F,aAAOtB,QAAQC,IAAI,CACf3D,MAAMC,MAAMgF,aAAaC,kBAAkBR,QAAQ,IAAI,GACvDS,sBACInF,OACA0E,MACJ,CAAC,CACJ,EAAErD,KAAK,CAAC,CACL+D,sBACAC,kBAAkB,MAChB;AACF,YAAMC,mBAAmB,oBAAIC,IAAuC;AACpEH,6BAAqBtB,QAAQ0B,SAAOF,iBAAiBG,IAAKD,IAAYnB,WAAW,GAAGmB,GAAG,CAAC;AACxF,eAAO9B,QAAQC,IACXe,OAAOgB,IAAI,OAAOnB,UAAU;AACxB,cAAMoB,mBAA0DL,iBAAiBM,IAAIrB,KAAK;AAC1F,cAAMsB,mBAAqEF,mBACrEG,mBAAmBH,kBAAkB3F,MAAM+F,gBAAgB,KAAK,IAChEC;AAEN,cAAMC,cAAczB,aAAaD,KAAK;AACtC,cAAM2B,gBAAgBb,mBAAmBd,KAAK;AAE9C,cACI2B,iBACAP,oBACAO,cAAcC,aAAaC,uBAAuBT,iBAAiBU,MACrE;AAOE,kBAAMrG,MAAMoB,YAAYsB;UAC5B;AAEA,cAAI4D,kCAAkC,CAACJ,iBAAiB,CAACL,mBACrD,QACA7F,MAAMC,MAAMsG,gBAAgBC,QACxBN,cAAc5B,SACduB,kBACA,6BACJ;AACJ,cACI,CAACS,mCAEGJ,iBACCA,cAAc5B,QAAgB+B,QAC/BV,oBACAA,iBAAiBc,MAAMzG,MAAMC,MAAMQ,UAAU,KAC7CiG,oBAAoBf,iBAAiBU,IAAI,MAAMV,iBAAiBc,MAAMzG,MAAMC,MAAMQ,UAAU,GAElG;AACE6F,8CAAkC;UACtC;AACA,cAEQX,oBACAO,iBACAI,oCAAoC,SAGpCX,oBAAoB,CAACO,eAE3B;AAOE,mBAAOhC;UACX;AAEA,cAAMyC,wBAAwB,CAACd,mBACzB,QACA7F,MAAMC,MAAMsG,gBAAgBC,QAC1BP,aACAJ,kBACA,6BACJ;AACJ,cACIA,oBACAc,uBACF;AASE,gBACI,CAACT,iBACDI,oCAAoC,OACtC;AACEtB,+BAAiB7D,KACb,MAAMyF,gBACF5G,OACA6F,kBACAK,gBAAgBA,cAAcC,eAAeH,MACjD,CACJ;YACJ;AACA,mBAAO9B;UACX;AAMA,cAAM2C,eAAelC,OAAOmC,OACxB,CAAC,GACDb,aACAN,mBAAmB;YACfc,OAAOM,UAAUpB,iBAAiBc,KAAK;YACvCO,cAAchH,MAAM+F,kBAAkBE,YAAYe,eAAef,YAAYe,eAAe,CAAC;YAC7FX,MAAMY,mBAAmB;UAC7B,IAAI;YACAR,OAAO;cACHS,KAAKC,IAAI;YACb;YACAd,MAAMY,mBAAmB;YACzBD,cAAchH,MAAM+F,kBAAkBE,YAAYe,eAAef,YAAYe,eAAe,CAAC;UACjG,CACJ;AASA,cAAKf,YAAoBI,MAAM;AAC3B,gBAAMe,qBAAqB,CAACzB,mBAAmB,IAAIe,oBAAoBf,iBAAiBU,IAAI,IAAI;AAChGQ,yBAAaJ,MAAMzG,MAAMC,MAAMQ,UAAU,IAAI2G;AAC7C,gBAAIpH,MAAMC,MAAMoH,UAAU;AACtBR,2BAAaR,OAAQJ,YAAoBI;YAC7C;UACJ;AACA,cACIrG,MAAMC,MAAMoH,YACXpB,YAAoBQ,OACvB;AACEI,yBAAaJ,QAASR,YAAoBQ;UAC9C;AAEA,cAAMa,eAAe;YACjBC,UAAU5B;YACV6B,UAAUX;UACd;AAEAS,uBAAaE,SAASnB,OAAOiB,aAAaE,SAASnB,OAAOiB,aAAaE,SAASnB,OAAOoB,eACnFlH,gBACA+G,aAAaC,QACjB;AACA1C,0BAAgB1D,KAAKmG,YAAY;AACjCxC,8BAAoBP,KAAK,IAAI+C;AAC7BvC,0BAAgBR,KAAK,IAAI,MAAMqC,gBAC3B5G,OACAiG,aACAC,gBAAgBA,cAAcC,eAAeH,MACjD;QACJ,CAAC,CACL;MACJ,CAAC,EAAE3E,KAAK,YAAY;AAChB,YAAIwD,gBAAgBtD,SAAS,GAAG;AAC5B,iBAAOvB,MAAMC,MAAMgF,aAAayC,UAC5B7C,iBACA,MAAM7E,MAAM2H,uBAChB,EAAEtG,KAAMuG,qBAAoB;AACxB,gBAAMC,UAAUC,yCACZ9H,MAAMqE,aACNQ,iBACA+C,eACJ;AACAC,oBAAQ/D,QAAQ0B,SAAO;AACnB,kBAAMjB,QAASiB,IAAYnB,WAAW;AACtCrE,oBAAMwB,OAAOuG,UAAU/G,KAAKU,KAAKoD,oBAAoBP,KAAK,CAAC;AAC3DS,+BAAiB7D,KAAK4D,gBAAgBR,KAAK,CAAC;YAChD,CAAC;AACD,gBAAIyD;AACJJ,4BAAgBK,MAAMnE,QAAQmE,WAAS;AAKnC,kBAAIA,MAAMC,WAAW,KAAK;AACtB;cACJ;AAEA,kBAAMC,UAAUC,WAAW,WAAW;gBAClCC,YAAYJ;cAChB,CAAC;AACDjI,oBAAMwB,OAAOyG,MAAMvG,KAAKyG,OAAO;AAC/BH,0BAAYG;YAChB,CAAC;AACD,gBAAIH,WAAW;AACX,oBAAMA;YACV;UACJ,CAAC;QACL;MACJ,CAAC,EAAE3G,KAAK,MAAM;AACV,YAAI2D,iBAAiBzD,SAAS,GAAG;AAC7B,iBAAOvB,MAAMC,MAAMqI,aAAaZ,UAC5Ba,sCAAsCvI,OAAOgF,gBAAgB,GAC7D,6BACJ,EAAE3D,KAAKmH,qBAAmB;AACtBA,4BAAgBP,MACXnE,QAAQuE,gBAAc;AACnBrI,oBAAMwB,OAAOyG,MAAMvG,KAAK0G,WAAW,WAAW;gBAC1CK,IAAIJ,WAAWK;gBACfL;cACJ,CAAC,CAAC;YACN,CAAC;UACT,CAAC;QACL;MACJ,CAAC,EAAEhH,KAAK,MAAM;AAMVf,sBACIN,OACA,QACAyE,aACJ;MACJ,CAAC;IACL,CAAC,EAAEkE,MAAMC,oBAAkB5I,MAAMwB,OAAOyG,MAAMvG,KAAKkH,cAAc,CAAC;AAClE,WAAO3E;EACX;AACJ;;;ACzfA,eAAsB4E,qBAClBC,OACAC,OACAC,WAC8C;AAC9C,MAAMC,kBAAgDH,MAAMC,MAAME;AAElE,MAAMC,UAAUD,gBAAgBC,QAAQH,MAAMI,iBAAiBJ,MAAMK,kBAAkB,8BAA8B;AAErH,MAAIF,SAAS;AAKT,WAAOG;EACX,OAAO;AACH,QAAMC,WAAW,MAAML,gBAAgBM,QAAQR,OAAO,8BAA8B;AAKpF,QAAMS,cAAyCC,OAAOC,OAClD,CAAC,GACDJ,UACA;;;;;MAKIK,OAAOC,UAAUZ,UAAUW,KAAK;MAChCE,MAAMC,mBAAmB;MACzBC,cAAcH,UAAUZ,UAAUe,YAAY;IAClD,CACJ;AACAP,gBAAYG,MAAMK,MAAMC,IAAI;AAC5BT,gBAAYK,OAAOK,eACf,MAAMpB,MAAMqB,eACZnB,SACJ;AACA,WAAOQ;EACX;AACJ;;;AC7CO,SAASY,0BAA0BC,YAAiB;AACvDC,SACKC,QAAQF,WAAWG,IAAIC,WAAWC,WAAW,EAC7CC,QAAQ,CAAC,CAACC,SAASC,GAAG,MAAM;AACzBP,WAAOQ,eAAeT,YAAYO,SAAS;MACvCG,KAAKA,MAAOF,IAAYG,KAAKX,UAAU;IAC3C,CAAC;EACL,CAAC;AACT;AAQA,eAAsBY,kCAClBC,aACAC,iBACAC,aACAC,kBAC6C;AAE7C,MACI,CAACD,YAAYE,gBAETD,oBACA,CAACA,iBAAiBC,cAExB;AACE,UAAM,IAAIC,MAAM,sBAAsB;EAC1C;AAEA,MAAMC,QAAiBJ,YAAoBF,WAAW;AACtD,MAAMO,yBAAyB,IAAIC,IAC/BL,oBAAoBA,iBAAiBC,eAC/BhB,OAAOqB,KAAKN,iBAAiBC,YAAY,IACzC,CAAA,CACV;AACA,QAAMM,QAAQC,IACVvB,OACKC,QAAQa,YAAYE,YAAY,EAChCQ,IAAI,OAAO,CAACC,KAAKC,KAAK,MAAM;AACzB,SAEQ,CAACP,uBAAuBQ,IAAIF,GAAG,KAE3BV,oBACAa,eAAeb,iBAAiBC,YAAY,EAAES,GAAG,EAAEI,WAAWH,MAAMG,WAG5E,CAAEH,MAAgCI,MACpC;AACE,UAAMC,uBAAuB,MAAMlB,gBAAgBmB,kBAC/Cd,OACAO,KACAC,MAAMG,MACV;AACCH,YAAgCI,OAAOC;IAC5C;EACJ,CAAC,CACT;AAEA,SAAOjB;AACX;;;AC/CA,IAAamB,eAAY,WAAA;AAMrB,WAAAA,cAAY;IACRC;IACAC;IACAC;IACAC;IACAC;EACC,GAAG;AACJ,SAAKJ,MAAMA;AACX,SAAKC,KAAKA;AACV,SAAKC,OAAOA;AACZ,SAAKC,SAASA;AACd,SAAKC,SAASA;AAEdC,8BAA0B,IAAI;EAClC;AAAC,MAAAC,SAAAP,cAAAQ;AAAAD,SAEDE,SAAA,SAAAA,SAAwB;AACpB,WAAO,KAAKR,IAAIS,WAAWC,sBAAsBC,SAC7C,KAAKX,IAAIY,OACTC,kBAAgB;AACZ,aAAOA,aAAaC,aAAa,KAAKb,EAAE;AACxC,aAAOY;IACX,CACJ,EAAEE,KAAK,MAAM;IAAE,CAAC;EACpB;AAEAT,SAGMU,UAAN,eAAMA,UAAyB;AAC3B,QAAMC,kBAAkB,MAAM,KAAKC,cAAc;AACjD,QAAMC,MAAM,MAAMC,qBACdH,iBACA,KAAKf,IACT;AACA,WAAOiB;EACX;AAACb,SAEKe,gBAAN,eAAMA,gBAAiC;AACnC,QAAMC,OAAO,MAAM,KAAKN,QAAQ;AAChC,QAAMO,WAAW,MAAMC,aAAaF,IAAI;AACxC,WAAOC;EACX;AAACjB,SAEKY,gBAAN,eAAMA,gBAAiC;AACnC,QAAMD,kBAAkB,MAAM,KAAKjB,IAAIS,WAAWgB,gBAAgBC,kBAC9D,KAAK1B,IAAI2B,SACT,KAAK1B,IACL,KAAKG,MACT;AACA,WAAOa;EACX;AAAC,SAAAlB;AAAA,EAAA;;;ACtCL,eAAsB6B,yBAClBC,OACF;AACE,MACIA,MAAMC,MAAMC,qBACZF,MAAMC,MAAMC,kBAAkBC,UAChC;AACE,QAAMC,gBAAgB,MAAMC,qBAAqBL,OAAO,IAAI;AAC5D,QAAI,CAACI,eAAe;AAChB,YAAME,cACFN,OACA,MACAA,MAAMC,MAAMC,kBAAkBC,QAClC;IACJ;EACJ;AAEA,MAAMI,qBAAqBP,MAAMC,MAAMM;AACvCP,QAAMQ,YAAYC,KAAKT,MAAMQ,YAAYC,GAAGC,KAAK,MAAM;AACnD,WAAOC,oBAAoB,EAAED,KAAK,MAAM;AACpC,aAAOE,aAAa;IACxB,CAAC;EACL,CAAC;AAGD,MAAIC,QAAQ;AACZ,MAAIC,uBAAuB;AAO3B,MAAMC,YAA4B,CAAA;AAClC,MAAIC,mBAAqCC;AACzC,MAAMC,yBAGF;IACAC,MAAM,CAAC;EACX;AAEA,MAAMC,MAAMpB,MAAMC,MAAMoB,aAAaC,aAAa,EAC7CC,UAAWC,eAAc;AACtB,QAAIxB,MAAMyB,OAAOC,OAAOC,SAAS,GAAG;AAChC;IACJ;AAGA3B,UAAM4B,MAAMnB,GAAGoB,uBAAuB7B,MAAM4B,MAAMnB,GAAGoB,uBAAuB;AAC5Ed,cAAUe,KAAK;MACXC,MAAMP;MACNQ,MAAMnB;IACV,CAAC;AACD,QAAI,CAACb,MAAMyB,OAAOQ,OAAOxB,GAAGkB,SAAS,GAAG;AACpC3B,YAAMyB,OAAOQ,OAAOxB,GAAGyB,KAAK,IAAI;IACpC;AACA,QAAIlC,MAAMC,MAAMkC,mBAAmB;AAC/B,aAAOnC,MAAMC,MAAMkC,kBAAkB,EAChCzB,KAAK,MAAME,aAAa,CAAC;IAClC,OAAO;AACH,aAAOA,aAAa;IACxB;EACJ,CAAC;AACL,MAAMwB,YAAY7B,mBACb8B,oBACAC,KACGC,OAAOC,QAAMA,OAAO,QAAQ,CAChC,EACCjB,UAAU,MAAM;AACbR,cAAUe,KAAK;MACXC,MAAM;MACNC,MAAMnB;IACV,CAAC;AACDD,iBAAa;EACjB,CAAC;AAGL6B,iBACIzC,MAAMyB,OAAOiB,SAASJ,KAClBC,OAAOG,cAAY,CAAC,CAACA,QAAQ,CACjC,CACJ,EAAEhC,KAAK,MAAM;AACTU,QAAIuB,YAAY;AAChBP,cAAUO,YAAY;EAC1B,CAAC;AAGD,iBAAehC,sBAAsB;AACjCX,UAAM4B,MAAMnB,GAAGE,sBAAsBX,MAAM4B,MAAMnB,GAAGE,sBAAsB;AAC1E,QAAIX,MAAMyB,OAAOiB,SAASf,SAAS,GAAG;AAClC;IACJ;AAEA3B,UAAM4C,kBAAkB5C,MAAM4C,gBAAgBlC,KAAK,MAAML,qBAAqBL,OAAO,IAAI,CAAC;AAC1F,QAAI6C,iBAAiC,MAAM7C,MAAM4C;AAEjD,QAAME,WAA8B,oBAAIC,IAAI;AAAE,QAAAC,QAAA,iBAEJ;AACtClC,6BAAuBD;AASvB,UAAIiC,SAASG,OAAO,GAAG;AACnB,cAAMC,QAAQC,KAAKC,MAAMC,KAAKP,QAAQ,CAAC;MAC3C;AACA,UAAMQ,WAAW,MAAMC,yBACnBvD,MAAMC,MAAMoB,cACZrB,MAAMC,MAAMuD,eACZX,cACJ;AACA,UAAIS,SAASG,UAAUC,WAAW,GAAG;AAAA,eAAA;MAErC;AAEAb,uBAAiBc,iBAAiB,CAACd,gBAAgBS,SAASM,UAAU,CAAC;AAEvE,UAAMC,UAAUC,gBACZR,SAASG,WACTM,eAAelB,cAAc,CACjC;AACAC,eAASkB,IAAIH,OAAO;AACpBA,cAAQI,MAAM,EAAEvD,KAAK,MAAMoC,SAASoB,OAAOL,OAAO,CAAC;IACvD;AA9BA,WAAO,CAAC7D,MAAMyB,OAAOiB,SAASf,SAAS,GAAC;AAAA,UAAA,MAAAqB,MAAA;AAmBhC;IAAM;AAkBd,QAAMmB,mBAAmB,MAAMjB,QAAQkB,IAAItB,QAAQ;AACnD,QAAMuB,eAAeF,iBAAiBG,KAAKC,OAAK,CAAC,CAACA,CAAC;AACnD,QAAIF,cAAc;AACd,YAAM1D,oBAAoB;IAC9B,WACI,CAACX,MAAMwE,cAAc/D,GAAGkB,SAAS,KACjC,CAAC3B,MAAMyB,OAAOiB,SAASf,SAAS,GAClC;AACE3B,YAAMwE,cAAc/D,GAAGyB,KAAK,IAAI;IACpC;EACJ;AAMA,WAAStB,eAAe;AACpB,QACIZ,MAAMyB,OAAOiB,SAASf,SAAS,KAC/BZ,UAAU2C,WAAW,GACvB;AACE1D,YAAMyB,OAAOQ,OAAOxB,GAAGyB,KAAK,KAAK;AACjC;IACJ;AACAlC,UAAM4B,MAAMnB,GAAGG,eAAeZ,MAAM4B,MAAMnB,GAAGG,eAAe;AAC5DZ,UAAMyB,OAAOQ,OAAOxB,GAAGyB,KAAK,IAAI;AAChClC,UAAMQ,YAAYC,KAAKT,MAAMQ,YAAYC,GAAGC,KAAK,YAAY;AAIzD,UAAMS,OAAoC,CAAA;AAC1C,UAAIyC;AACJ,aAAO7C,UAAU2C,SAAS,GAAG;AACzB,YAAMe,eAAeV,eAAehD,UAAU2D,MAAM,CAAC;AAMrD,YAAID,aAAazC,OAAOlB,sBAAsB;AAC1C;QACJ;AAEA,YAAI2D,aAAa1C,SAAS,UAAU;AAChC/B,gBAAMyB,OAAOQ,OAAOxB,GAAGyB,KAAK,KAAK;AACjC,gBAAMvB,oBAAoB;AAC1B;QACJ;AAQA,YAAI8D,aAAa1C,KAAK4C,YAAY,MAAM3E,MAAM4E,yBAAyB;AACnEC,wBACI1D,MACAsD,aAAa1C,KAAKN,OAAOqD,IAAIP,OAAK;AAC9B,mBAAOA,EAAEQ;UACb,CAAC,CACL;QACJ;AACAnB,qBAAaD,iBAAiB,CAACC,YAAYa,aAAa1C,KAAK6B,UAAU,CAAC;MAC5E;AAEA,YAAME,gBACF3C,MACAyC,UACJ;AAGA,UAAI7C,UAAU2C,WAAW,GAAG;AACxB1D,cAAMyB,OAAOQ,OAAOxB,GAAGyB,KAAK,KAAK;MACrC,OAAO;AACH,eAAOtB,aAAa;MACxB;IACJ,CAAC;EACL;AAMA,WAASkD,gBACL3C,MACAyC,YACgB;AAChB5D,UAAM4B,MAAMnB,GAAGqD,kBAAkB9D,MAAM4B,MAAMnB,GAAGqD,kBAAkB;AAKlE3C,SAAK6D,QAAQC,aAAW;AACpB,UAAMC,QAAiBD,QAAgBjF,MAAMmF,WAAW;AACxDjE,6BAAuBC,KAAK+D,KAAK,IAAID;IACzC,CAAC;AACD/D,2BAAuB0C,aAAaA;AAEpC5C,uBAAmBA,iBAAiBN,KAAK,YAAY;AACjD,UAAIV,MAAMyB,OAAOiB,SAASf,SAAS,GAAG;AAClC,eAAO;MACX;AAEA,UAAMyD,aAA8ClE,uBAAuBC;AAC3ED,6BAAuBC,OAAO,CAAC;AAC/B,UAAMkE,gBAAgBnE,uBAAuB0C;AAC7C,UAAM0B,SAASC,OAAOC,KAAKJ,UAAU;AASrC,eAASK,iCAAiC;AACtC,eAAOnF,cACHN,OACA,MACAqF,aACJ;MACJ;AAAC;AAGD,UAAIC,OAAO5B,WAAW,GAAG;AACrB+B,uCAA+B;AAC/B,eAAO;MACX;AAEA,UAAMC,qBAAqB,MAAMC,sBAC7B3F,OACAsF,MACJ;AAEA,UAAMM,oBAAoE,CAAC;AAC3E,UAAMC,uBAAiC,CAAA;AACvC,UAAMC,kBAA8E,CAAC;AACrF,UAAMC,gBAAiD,CAAC;AAExD,YAAM7C,QAAQkB,IACVkB,OAAOR,IAAI,OAAOI,UAAU;AACxB,YAAMc,cAAyCZ,WAAWF,KAAK;AAC/Da,sBAAcb,KAAK,IAAIc;AACvB,YAAMf,UAAkCgB,mBAAmBD,aAAahG,MAAMkG,gBAAgB,CAAC,CAAClG,MAAMC,MAAMkG,QAAQ;AACpH,YAAMC,mBAAmBV,mBAAmBR,KAAK;AAOjD,YAEQkB;QAEAA,iBAAiBC,aAAaC,uBAAuBN,YAAYO,QAG7DvG,MAAMC,MAAMuG,gBAAgBC,QACxBL,iBAAiBnB,SACjBA,SACA,yBACJ;;;;;QAUJmB,oBACCA,iBAAiBnB,QAAgBsB,QAClCG,oBAAoBV,YAAYO,IAAI,MAAMP,YAAYW,MAAM3G,MAAMC,MAAM2G,UAAU,GAExF;AACE;QACJ;AAEAf,6BAAqB/D,KAAKoD,KAAK;AAE/BU,0BAAkBV,KAAK,IAAI;UACvBQ,oBAAoBU,mBAAmBA,iBAAiBnB,UAAU4B;UAClEC,kBAAkB7B;QACtB;AACAa,wBAAgBZ,KAAK,IAAI,MAAM6B,gBAC3B/G,OACAiF,SACAmB,mBAAmBA,iBAAiBC,eAAeQ,MACvD;MACJ,CAAC,CACL;AAEA,UAAIhB,qBAAqBnC,WAAW,GAAG;AACnC+B,uCAA+B;AAC/B,eAAO;MACX;AAGA,UAAMuB,iBAAiBzB,OAAO0B,OAAOrB,iBAAiB;AACtD,UAAMsB,cAA2B,oBAAInE,IAAI;AACzC,UAAMoE,gBAA8C,CAAC;AAQrD,UAAMC,eAAeC,WAAWL,gBAAgBhH,MAAMC,MAAMuD,aAAa;AACzE,YAAMN,QAAQkB,IACVgD,aAAatC,IAAI,OAAOwC,eAAe;AAGnC,YAAItH,MAAMkG,gBAAgB;AACtB,gBAAMhD,QAAQkB,IACVkD,WAAWxC,IAAI,OAAOyC,QAAQ;AAC1BA,gBAAIT,mBAAmB,MAAMU,kCACzBxH,MAAMmF,aACNnF,MAAMC,MAAMoB,cACZoG,MAAMF,IAAIT,gBAAgB,GAC1BS,IAAI7B,kBACR;UACJ,CAAC,CACL;QACJ;AACA,YAAMgC,oBAAoB,MAAMnH,mBAAmBoH,YAAYL,UAAU;AACzEI,0BAAkB1C,QAAQ4C,iBAAe;AACrC,cAAMC,KAAMD,YAAoB5H,MAAMmF,WAAW;AACjD+B,sBAAYlD,IAAI6D,EAAE;AAClBV,wBAAcU,EAAE,IAAID;QACxB,CAAC;MACL,CAAC,CACL;AAEA,UAAME,qBAA+E,CAAA;AAErFjC,2BAAqBb,QAAQE,WAAS;AAClC,YAAI,CAACgC,YAAYa,IAAI7C,KAAK,GAAG;AACzBlF,gBAAMyB,OAAOuG,UAAUvH,GAAGyB,KAAK0D,kBAAkBV,KAAK,CAAC;AACvD4C,6BAAmBhG,KAAKgE,gBAAgBZ,KAAK,CAAC;QAClD;MACJ,CAAC;AAED,UAAIlF,MAAMyB,OAAOiB,SAASf,SAAS,GAAG;AAClC,eAAO;MACX;AAEA,UAAImG,mBAAmBpE,SAAS,GAAG;AAC/B,cAAM1D,MAAMC,MAAMgI,aAAaC,UAC3BC,sCAAsCnI,OAAO8H,kBAAkB,GAC/D,2BACJ;MAEJ;AAQA,UAAIM,oBAAoB;AACxB,UAAIlB,YAAYjE,OAAO,GAAG;AACtBjD,cAAM4B,MAAMnB,GAAG4H,8BAA8BrI,MAAM4B,MAAMnB,GAAG4H,8BAA8B;AAC1F,YAAMC,oBAA+C,CAAA;AACrD,YAAMC,oBAAgF,CAAC;AACvF,cAAMrF,QAAQkB,IACVmB,OACKiD,QAAQrB,aAAa,EACrBrC,IAAI,CAAC,CAACI,OAAOuD,eAAe,MAAM;AAC/B,cAAMC,mBAAmB9C,kBAAkBV,KAAK;AAChD,cAAMjF,QAAQ;YACV6G,kBAAkB4B,iBAAiB5B;YACnCpB,oBAAoBgD,iBAAiBhD;YACrC+C;UACJ;AACA,iBAAOE,qBACH3I,OACAC,OACA8F,cAAcb,KAAK,CACvB,EAAExE,KAAK,OAAOkI,aAAa;AACvB,gBAAIA,UAAU;AACV5I,oBAAMyB,OAAOoH,kBAAkB3G,KAAK;gBAChCjC;gBACA6I,QAAQF;cACZ,CAAC;AACDN,gCAAkBxG,KAAK;gBACnBiH,UAAUhD,cAAcb,KAAK;gBAC7B8D,UAAUJ;cACd,CAAC;AACD,kBAAMxC,mBAAmBV,mBAAmBR,KAAK;AACjDqD,gCAAkBrD,KAAK,IAAI,MAAM6B,gBAC7B/G,OACA+D,eAAe0E,eAAe,GAC9BrC,mBAAmBA,iBAAiBC,eAAeQ,QACnD+B,SAASrC,IACb;YACJ;UACJ,CAAC;QACL,CAAC,CACT;AAEA,YAAI+B,kBAAkB5E,SAAS,GAAG;AAC9B0E,8BAAoB;AAEpBpI,gBAAM4B,MAAMnB,GAAGwI,gCAAgCjJ,MAAM4B,MAAMnB,GAAGwI,gCAAgC;AAC9F,cAAMC,kBAAkB,MAAMlJ,MAAMC,MAAMoB,aAAa6G,UACnDI,mBACA,+BACJ;AAEA,cAAIa;AACJD,0BAAgBE,MAAMpE,QAAQoE,WAAS;AAOnC,gBAAIA,MAAMC,WAAW,KAAK;AACtB;YACJ;AAEA,gBAAMC,UAAUC,WAAW,WAAW;cAClCC,YAAYJ;YAChB,CAAC;AACDpJ,kBAAMyB,OAAO2H,MAAMlH,KAAKoH,OAAO;AAC/BH,wBAAYG;UAChB,CAAC;AACD,cAAIH,WAAW;AACX,kBAAMA;UACV;AAEA,cAAMM,gBAA0E,CAAA;AAChF,cAAMC,UAAUC,yCACZ3J,MAAMmF,aACNmD,mBACAY,eACJ;AACAQ,kBACK1E,QAAQC,aAAW;AAChB,gBAAMC,QAASD,QAAgBjF,MAAMmF,WAAW;AAChDsE,0BAAc3H,KACVyG,kBAAkBrD,KAAK,CAC3B;UACJ,CAAC;AACL,cAAIuE,cAAc/F,SAAS,GAAG;AAC1B,kBAAM1D,MAAMC,MAAMgI,aAAaC,UAC3BC,sCAAsCnI,OAAOyJ,aAAa,GAC1D,oCACJ;UACJ;QAEJ;MACJ;AAOAhE,qCAA+B;AAE/B,aAAO2C;IACX,CAAC,EAAEnE,MAAM2F,oBAAkB;AACvB5J,YAAMyB,OAAO2H,MAAMlH,KAAK0H,cAAc;AACtC,aAAO;IACX,CAAC;AAED,WAAO5I;EACX;AACJ;;;AC1fO,SAAS6I,2BACZC,OAC4C;AAC5CA,UAAQC,UAAUD,KAAK;AACvBA,QAAME,eAAeC,+BAA+BH,MAAME,YAAY;AACtEF,QAAMI,eAAeD,+BAA+BH,MAAMI,YAAY;AACtE,MAAMC,uBAAuBC,iBAAiBN,KAAK;AACnD,MAAMO,QAAsD;IACxDC,aAAaC,4BAA4BT,MAAME,aAAaQ,OAAOC,UAAU;IAC7EC,gBAAgB,CAAC,CAACZ,MAAME,aAAaQ,OAAOG;IAC5Cb;IACAc,eAAeT;IACfU,yBAAyBV,qBAAqBW,KAAKF,mBAAiB,4BAA4BA,aAAa;IAC7GG,QAAQ;MACJC,UAAU,IAAIC,gBAAyB,KAAK;MAC5CC,QAAQ,IAAID,gBAAyB,KAAK;MAC1CE,QAAQ;QACJC,MAAM,IAAIH,gBAAyB,IAAI;QACvCI,IAAI,IAAIJ,gBAAyB,IAAI;MACzC;MACAK,WAAW;QACPF,MAAM,IAAIG,QAAQ;QAClBF,IAAI,IAAIE,QAAQ;MACpB;MACAC,mBAAmB,IAAID,QAAQ;MAC/BE,OAAO,IAAIF,QAAQ;IACvB;IACAG,OAAO;MACHN,MAAM;QACFO,YAAY;QACZC,0BAA0B;QAC1BC,sBAAsB;QACtBC,wBAAwB;QACxBC,mBAAmB;MACvB;MACAV,IAAI;QACAW,sBAAsB;QACtBC,iBAAiB;QACjBC,+BAA+B;QAC/BC,6BAA6B;QAC7BC,cAAc;QACdC,qBAAqB;MACzB;IACJ;IACAC,eAAe;MACXlB,MAAM,IAAIH,gBAAyB,KAAK;MACxCI,IAAI,IAAIJ,gBAAyB,KAAK;IAC1C;IACAsB,aAAa;MACTnB,MAAMoB;MACNnB,IAAImB;IACR;IACAC,iBAAiBD;IACjBE,mBAAmB,CAAC;EACxB;AAEAC,6BAA2BtC,KAAK;AAChCuC,2BAAyBvC,KAAK;AAC9B,SAAOA;AACX;AAEO,SAASwC,qCACZxC,OACa;AACb,SAAOyC,eACHC,cAAc,CACV1C,MAAMiC,cAAclB,KAAK4B,KACrBC,OAAOC,OAAK,CAAC,CAACA,CAAC,CACnB,GACA7C,MAAMiC,cAAcjB,GAAG2B,KACnBC,OAAOC,OAAK,CAAC,CAACA,CAAC,CACnB,CAAC,CACJ,CACL,EAAEpC,KAAK,MAAM;EAAE,CAAC;AACpB;AAEO,SAASqC,gCACZC,kBACF;AACE,SAAOC,QAAQC,IAAI,CACfF,iBAAiBb,YAAYlB,IAC7B+B,iBAAiBb,YAAYnB,MAC7BgC,iBAAiBX,eAAe,CACnC;AACL;AAGA,eAAsBc,8BAClBlD,OACF;AACE,QAAMwC,qCAAqCxC,KAAK;AAChD,SAAO,MAAM;AACT,QAAM;MAAEe;MAAMC;IAAG,IAAIhB,MAAMkC;AAC3B,UAAMc,QAAQC,IAAI,CACdjC,IACAD,IAAI,CACP;AAMD,QACIA,SAASf,MAAMkC,YAAYnB,QAC3BC,OAAOhB,MAAMkC,YAAYlB,IAC3B;AACE;IACJ;EACJ;AACJ;AAGO,SAASmC,sCACZC,UACAC,iBACAC,uBAMAC,WAAoB,OACiC;AACrDH,aAAWxD,+BAA+BwD,QAAQ;AAElD,MAAM/C,iBAAiB,CAAC,CAAC+C,SAASjD,OAAOG;AACzC,MAAML,cAAcC,4BAA4BkD,SAASjD,OAAOC,UAAU;AAC1E,MAAMoD,qBAA4E;IAC9EC,qBAAqBL,SAASM,aAAa,EAAEf,KACzCgB,SAAS,OAAOC,cAAc;AAC1B,UAAMC,MAAgE;QAClEC,YAAYF,UAAUE;QACtBC,WAAW,MAAMf,QAAQC,IACrBW,UAAUlD,OAAOsD,IAAI,OAAOC,UAAU;AAClC,cAAIC,UAAUC,mBAAmBF,MAAMG,cAAc/D,gBAAgBkD,QAAQ;AAC7E,cAAIlD,gBAAgB;AAChB6D,sBAAU,MAAMG;cACZpE;cACAmD;cACAkB,MAAMJ,OAAO;;;;;;cAMbK;YACJ;UACJ;AACA,iBAAOL;QACX,CAAC,CACL;MACJ;AACA,aAAOL;IACX,CAAC,CACL;IACAW,mBACIV,YACAW,WACF;AACE,aAAOC,yBACHtB,UACAqB,WACAX,UACJ,EAAErD,KAAK,OAAOkE,WAAW;AACrB,eAAO;UACHb,YAAYa,OAAOZ,UAAUa,SAAS,IAAID,OAAOb,aAAaA;UAC9DC,WAAW,MAAMf,QAAQC,IACrB0B,OAAOZ,UAAUC,IAAI,OAAOa,sBAAsB;AAC9C,gBAAIX,UAAUC,mBAAmBU,mBAAmBxE,gBAAgBkD,QAAQ;AAC5E,gBAAIlD,gBAAgB;AAChB6D,wBAAU,MAAMG;gBACZpE;gBACAmD;gBACAkB,MAAMJ,OAAO;;;;;;gBAMbK;cACJ;YACJ;AACA,mBAAOL;UACX,CAAC,CACL;QACJ;MACJ,CAAC;IACL;IACA,MAAMY,YACFC,MACF;AACE,UAAMC,UAA0D,CAAC;AACjED,WAAKE,QAAQC,SAAO;AAChB,YAAMC,QAAiBD,IAAIE,iBAAyBnF,WAAW;AAC/D+E,gBAAQG,KAAK,IAAID;MACrB,CAAC;AACD,UAAMG,MAAMC,OAAOC,KAAKP,OAAO;AAE/B,UAAMQ,sBAAsB,MAAMpC,SAASqC,kBACvCJ,KACA,IACJ;AACA,UAAMK,kBAAkB,oBAAIC,IAAuC;AACnEH,0BAAoBP,QAAQW,SAAOF,gBAAgBG,IAAKD,IAAY3F,WAAW,GAAG2F,GAAG,CAAC;AACtF,UAAME,YAAsC,CAAA;AAC5C,UAAMC,YAAuC,CAAA;AAC7C,YAAM/C,QAAQC,IACVqC,OAAOU,QAAQhB,OAAO,EACjBhB,IAAI,CAAC,CAACiC,IAAIf,GAAG,MAAM;AAChB,YAAMgB,cAAcR,gBAAgBS,IAAIF,EAAE;AAC1C,YAAI,CAACC,aAAa;AACdH,oBAAUK,KAAK;YACXC,UAAUC,mBAAmBhD,uBAAuBjD,gBAAgBkD,UAAU2B,IAAIE,gBAAgB;UACtG,CAAC;QACL,WACIc,eACA,CAAChB,IAAIqB,oBACP;AACET,oBAAUM,KAAKjC,mBAAmB+B,aAAa7F,gBAAgBkD,QAAQ,CAAC;QAC5E,WACIF,gBAAgBmD,QACZrC,mBAAmB+B,aAAa7F,gBAAgBkD,QAAQ,GACxDkD,eAAevB,IAAIqB,kBAAkB,GACrC,mDACJ,MAAM,MACR;AACER,oBAAUK,KAAK;YACXM,UAAUR;YACVG,UAAUC,mBAAmBhD,uBAAuBjD,gBAAgBkD,UAAU2B,IAAIE,kBAAkBc,WAAW;UACnH,CAAC;QACL,OAAO;AACHJ,oBAAUM,KAAKjC,mBAAmB+B,aAAa7F,gBAAgBkD,QAAQ,CAAC;QAC5E;MACJ,CAAC,CACT;AAEA,UAAIwC,UAAUnB,SAAS,GAAG;AACtB,YAAMD,SAAS,MAAMvB,SAASuD,UAC1BZ,WACA,0BACJ;AAEApB,eAAOvD,MAAM6D,QAAQ2B,SAAO;AACxB,cAAIA,IAAIC,WAAW,KAAK;AACpB,kBAAMC,WAAW,OAAO;cACpBC,MAAM;cACN3F,OAAOwF;YACX,CAAC;UACL,OAAO;AACHd,sBAAUM,KACNjC,mBAAmBsC,eAAeG,IAAII,YAAY,GAAG3G,gBAAgBkD,QAAQ,CACjF;UACJ;QACJ,CAAC;MACL;AACA,aAAOuC;IACX;EACJ;AAEA,SAAOtC;AACX;AAGA,eAAsByD,2BAClBlE,kBACF;AACEA,mBAAiBrC,OAAOC,SAASuG,KAAK,IAAI;AAC1CnE,mBAAiBrC,OAAOI,OAAOE,GAAGmG,SAAS;AAC3CpE,mBAAiBrC,OAAOI,OAAOC,KAAKoG,SAAS;AAC7CpE,mBAAiBrC,OAAOO,UAAUD,GAAGmG,SAAS;AAC9CpE,mBAAiBrC,OAAOO,UAAUF,KAAKoG,SAAS;AAChDpE,mBAAiBrC,OAAOS,kBAAkBgG,SAAS;AACnDpE,mBAAiBrC,OAAOC,SAASwG,SAAS;AAC1C,QAAMpE,iBAAiBX;AAC3B;;;AC3RO,SAASgF,aACZC,QACAC,OAC2B;AAC3B,MAAMC,sBAAmDD,MAAME,IAAIC,eAAa;AAC5E,QAAMC,aAAaC,sBACfN,QACAI,SACJ;AACA,QAAI,CAACC,YAAY;AACb,YAAM,IAAIE,MAAM,oBAAoBH,SAAS;IACjD;AACA,QAAMI,OAAOH,WAAWG;AACxB,QAAIC;AACJ,QAAID,SAAS,YAAYA,SAAS,WAAW;AACzCC,sBAAgBC,6BACZL,UACJ;IACJ;AAEA,QAAMM,WAAWC,gBAAgBR,SAAS;AAC1C,QAAMS,YAAYR,WAAWQ,YAAYR,WAAWQ,YAAY;AAEhE,QAAIC;AACJ,QAAIN,SAAS,UAAU;AACnBM,2BAAqBC,aAAW;AAC5B,YAAIC,aAAaL,SAASI,OAAO;AACjC,YAAI,CAACC,YAAY;AACbA,uBAAa;QACjB;AACA,eAAOA,WAAWC,OAAOJ,WAAW,GAAG;MAC3C;IACJ,WAAWL,SAAS,WAAW;AAC3BM,2BAAqBC,aAAW;AAC5B,YAAMC,aAAaL,SAASI,OAAO;AACnC,eAAOC,aAAa,MAAM;MAC9B;IACJ,OAAO;AACHF,2BAAqBC,aAAW;AAC5B,YAAMC,aAAaL,SAASI,OAAO;AACnC,eAAOG,qBACHT,eACAO,UACJ;MACJ;IACJ;AAEA,QAAMG,MAAiC;MACnCf;MACAC;MACAI;MACAE;MACAG;IACJ;AACA,WAAOK;EACX,CAAC;AACD,SAAOjB;AACX;AAcO,SAASkB,wBACZpB,QACAC,OAC8C;AAC9C,MAAMC,sBAAsBH,aAAaC,QAAQC,KAAK;AACtD,MAAMoB,4BAA4BnB,oBAAoBoB;AACtD,MAAMC,sBAAsBrB,oBAAoBC,IAAIqB,OAAKA,EAAEV,kBAAkB;AAM7E,MAAMK,MAAM,SAAUJ,SAA4C;AAC9D,QAAIU,MAAM;AACV,aAASC,IAAI,GAAGA,IAAIL,2BAA2B,EAAEK,GAAG;AAChDD,aAAOF,oBAAoBG,CAAC,EAAEX,OAAO;IACzC;AACA,WAAOU;EACX;AACA,SAAON;AACX;AAUO,SAAST,6BACZL,YACa;AACb,MAAMsB,UAAUC,KAAKC,MAAMxB,WAAWsB,OAAiB;AACvD,MAAMG,UAAUF,KAAKG,KAAK1B,WAAWyB,OAAiB;AACtD,MAAME,aAAqB3B,WAAW2B;AAEtC,MAAMC,YAAYH,UAAUH;AAC5B,MAAMO,cAAcD,UAAUE,SAAS,EAAEb;AAEzC,MAAMc,kBAAkBJ,WAAWG,SAAS,EAAEE,MAAM,GAAG;AACvD,MAAIC,WAAW;AACf,MAAIF,gBAAgBd,SAAS,GAAG;AAC5BgB,eAAWF,gBAAgB,CAAC,EAAEd;EAClC;AACA,SAAO;IACHK;IACAG;IACAI;IACAI;IACAC,gBAAgBZ;EACpB;AACJ;AAEO,SAASa,qBACZxC,QACAC,OACM;AACN,MAAMC,sBAAsBH,aAAaC,QAAQC,KAAK;AACtD,MAAIqB,SAAS;AACbpB,sBAAoBuC,QAAQC,WAAS;AACjC,QAAMrC,aAAaqC,MAAMrC;AACzB,QAAMG,OAAOH,WAAWG;AAExB,QAAIA,SAAS,UAAU;AACnBc,gBAAUjB,WAAWQ;IACzB,WAAWL,SAAS,WAAW;AAC3Bc,gBAAU;IACd,OAAO;AACH,UAAMb,gBAAgBiC,MAAMjC;AAC5Ba,eAASA,SAASb,cAAcyB,cAAczB,cAAc6B;IAChE;EAEJ,CAAC;AACD,SAAOhB;AACX;AAGO,SAASqB,iCACZC,iBACAC,kBACM;AACN,MAAMC,mBAAmBF,gBAAgBG,MAAMF,mBAAmB,EAAE;AAEpE,MAAMG,aAAaF,iBAAiBG,KAAK;AACzC,SAAOD;AACX;AAGO,SAAS9B,qBACZT,eACAO,YACM;AAUN,MAAI,OAAOA,eAAe,aAAa;AACnCA,iBAAa;EACjB;AACA,MAAIA,aAAaP,cAAckB,SAAS;AACpCX,iBAAaP,cAAckB;EAC/B;AACA,MAAIX,aAAaP,cAAcqB,SAAS;AACpCd,iBAAaP,cAAcqB;EAC/B;AAEA,MAAMoB,4BAA4BtB,KAAKC,MAAMb,UAAU,IAAIP,cAAc8B,gBAAgBJ,SAAS;AAClG,MAAIV,MAAMyB,yBAAyBC,SAAS1C,cAAcyB,aAAa,GAAG;AAE1E,MAAIzB,cAAc6B,WAAW,GAAG;AAC5B,QAAMc,sBAAsBpC,WAAWmB,SAAS,EAAEE,MAAM,GAAG;AAC3D,QAAMgB,uBAAuBD,oBAAoB9B,SAAS,IAAI8B,oBAAoB,CAAC,IAAI;AACvF3B,WAAO4B,qBAAqBpC,OAAOR,cAAc6B,UAAU,GAAG;EAClE;AACA,SAAOb;AACX;AAEO,SAAS6B,kCACZtD,QACAC,OACAsD,YACM;AACN,MAAI9B,MAAM;AACVxB,QAAMwC,QAAQ,CAACrC,WAAWoD,QAAQ;AAC9B,QAAMnD,aAAaC,sBACfN,QACAI,SACJ;AACA,QAAMqD,QAAQF,WAAWC,GAAG;AAC5B,QAAMhD,OAAOH,WAAWG;AAExB,YAAQA,MAAI;MACR,KAAK;AACD,YAAMK,YAAY6C,eAAerD,WAAWQ,WAAW,mBAAmB;AAC1E,YAAI,OAAO4C,UAAU,UAAU;AAC3BhC,iBAAQgC,MAAiBxC,OAAOJ,WAAW,GAAG;QAClD,OAAO;AAEHY,iBAAO,GAAGR,OAAOJ,WAAW,GAAG;QACnC;AACA;MACJ,KAAK;AACD,YAAI4C,UAAU,MAAM;AAChBhC,iBAAO;QACX,WAAWgC,UAAUE,WAAW;AAC5BlC,iBAAO;QACX,WAAWgC,UAAUG,WAAW;AAC5BnC,iBAAO;QACX,OAAO;AACH,cAAMoC,YAAYJ,QAAQ,MAAM;AAChChC,iBAAOoC;QACX;AACA;MACJ,KAAK;MACL,KAAK;AACD,YAAMpD,gBAAgBC,6BAClBL,UACJ;AACA,YAAIoD,UAAU,QAAQA,UAAUE,WAAW;AACvC,cAAMG,WAAW;AACjBrC,iBAAOqC,SAASC,OAAOtD,cAAcyB,cAAczB,cAAc6B,QAAQ;QAC7E,WAAWmB,UAAUG,WAAW;AAC5BnC,iBAAOP,qBACHT,eACAA,cAAcqB,OAClB;QACJ,OAAO;AACH,cAAMkC,MAAM9C,qBACRT,eACAgD,KACJ;AACAhC,iBAAOuC;QACX;AACA;MACJ;AACI,cAAM,IAAIzD,MAAM,wBAAwBC,IAAI;IACpD;EACJ,CAAC;AACD,SAAOiB;AACX;AAGO,SAASwC,kCACZjE,QACAC,OACAiE,YACM;AACN,MAAIzC,MAAM;AACVxB,QAAMwC,QAAQ,CAACrC,WAAWoD,QAAQ;AAC9B,QAAMnD,aAAaC,sBACfN,QACAI,SACJ;AACA,QAAMqD,QAAQS,WAAWV,GAAG;AAC5B,QAAMhD,OAAOH,WAAWG;AAExB,YAAQA,MAAI;MACR,KAAK;AACD,YAAMK,YAAY6C,eAAerD,WAAWQ,WAAW,mBAAmB;AAC1E,YAAI,OAAO4C,UAAU,YAAYA,UAAUG,WAAW;AAClDnC,iBAAQgC,MAAiBxC,OAAOJ,WAAW,GAAG;QAClD,WAAW4C,UAAUE,WAAW;AAC5BlC,iBAAO,GAAGR,OAAOJ,WAAW,GAAG;QACnC,OAAO;AACHY,iBAAO,GAAGR,OAAOJ,WAAW+C,SAAS;QACzC;AACA;MACJ,KAAK;AACD,YAAIH,UAAU,MAAM;AAChBhC,iBAAO;QACX,OAAO;AACH,cAAMoC,YAAYJ,QAAQ,MAAM;AAChChC,iBAAOoC;QACX;AACA;MACJ,KAAK;MACL,KAAK;AACD,YAAMpD,gBAAgBC,6BAClBL,UACJ;AACA,YAAIoD,UAAU,QAAQA,UAAUG,WAAW;AACvC,cAAME,WAAW;AACjBrC,iBAAOqC,SAASC,OAAOtD,cAAcyB,cAAczB,cAAc6B,QAAQ;QAC7E,WAAWmB,UAAUE,WAAW;AAC5B,cAAMG,YAAW;AACjBrC,iBAAOqC,UAASC,OAAOtD,cAAcyB,cAAczB,cAAc6B,QAAQ;QAC7E,OAAO;AACHb,iBAAOP,qBACHT,eACAgD,KACJ;QACJ;AACA;MACJ;AACI,cAAM,IAAIlD,MAAM,wBAAwBC,IAAI;IACpD;EACJ,CAAC;AACD,SAAOiB;AACX;AAMO,SAAS0C,kCAAkC1C,KAAa2C,WAA2B;AACtF,MAAMC,WAAW5C,IAAIsB,MAAM,EAAE;AAC7B,MAAIuB,WAAWD,SAASE,WAAW,CAAC;AACpCD,aAAWA,WAAWF;AACtB,MAAMI,kBAAkB/C,IAAIsB,MAAM,GAAG,EAAE;AACvC,SAAOyB,kBAAkBC,OAAOC,aAAaJ,QAAQ;AACzD;",
  "names": ["PROTOTYPES", "RxSchema", "prototype", "RxDocument", "RxDocumentPrototype", "RxQuery", "RxQueryBase", "RxCollection", "RxCollectionBase", "RxDatabase", "RxDatabaseBase", "ADDED_PLUGINS", "Set", "ADDED_PLUGIN_NAMES", "addRxPlugin", "plugin", "runPluginHooks", "plugins", "has", "name", "newRxError", "add", "rxdb", "newRxTypeError", "init", "prototypes", "Object", "entries", "forEach", "fun", "overwritable", "assign", "hooks", "hooksObj", "after", "HOOKS", "push", "before", "unshift", "getLastCheckpointDoc", "state", "direction", "checkpointDocId", "getComposedPrimaryKeyOfDocumentData", "input", "metaInstance", "schema", "isCheckpoint", "itemId", "checkpointResult", "findDocumentsById", "checkpointDoc", "lastCheckpointDoc", "checkpointData", "undefined", "setCheckpoint", "checkpoint", "checkpointQueue", "then", "previousCheckpointDoc", "events", "canceled", "getValue", "JSON", "stringify", "newDoc", "id", "_deleted", "_attachments", "_meta", "getDefaultRxDocumentMeta", "_rev", "getDefaultRevision", "stackCheckpoints", "lwt", "now", "createRevision", "checkpointKey", "writeRows", "previous", "document", "result", "bulkWrite", "successDoc", "getWrittenDocumentsFromBulkWriteResponse", "primaryPath", "error", "status", "ensureNotFalsy", "documentInDb", "getCheckpointKey", "hash", "hashFunction", "identifier", "forkInstance", "databaseName", "collectionName", "join", "docStateToWriteDoc", "databaseInstanceToken", "hasAttachments", "keepMeta", "docState", "previous", "docData", "Object", "assign", "_attachments", "_meta", "lwt", "now", "_rev", "getDefaultRevision", "createRevision", "writeDocToDocState", "writeDoc", "keepAttachments", "ret", "flatClone", "stripAttachmentsDataFromMetaWriteRows", "state", "rows", "map", "row", "document", "clone", "stripAttachmentsDataFromDocument", "getUnderlyingPersistentStorage", "instance", "underlyingPersistentStorage", "META_INSTANCE_SCHEMA_TITLE", "getRxReplicationMetaInstanceSchema", "replicatedDocumentsSchema", "encrypted", "parentPrimaryKeyLength", "getLengthOfPrimaryKey", "baseSchema", "title", "primaryKey", "key", "fields", "separator", "type", "version", "additionalProperties", "properties", "id", "minLength", "maxLength", "isCheckpoint", "enum", "itemId", "checkpointData", "docData", "isResolvedConflict", "keyCompression", "required", "metaInstanceSchema", "fillWithDefaultSettings", "getAssumedMasterState", "state", "docIds", "input", "metaInstance", "findDocumentsById", "map", "docId", "useId", "getComposedPrimaryKeyOfDocumentData", "schema", "then", "metaDocs", "ret", "Object", "values", "forEach", "metaDoc", "metaDocument", "getMetaWriteRow", "newMasterDocState", "previous", "primaryPath", "newMeta", "flatCloneDocWithMeta", "_attachments", "_deleted", "_rev", "getDefaultRevision", "_meta", "lwt", "now", "createRevision", "checkpointKey", "document", "startReplicationDownstream", "state", "input", "initialCheckpoint", "downstream", "checkpointDoc", "getLastCheckpointDoc", "setCheckpoint", "identifierHash", "hashFunction", "identifier", "replicationHandler", "timer", "openTasks", "addNewTask", "task", "stats", "down", "taskWithTime", "time", "push", "streamQueue", "then", "useTasks", "length", "events", "active", "next", "innerTaskWithTime", "ensureNotFalsy", "shift", "lastTimeMasterChangesRequested", "downstreamResyncOnce", "downstreamProcessChanges", "firstSyncDone", "getValue", "canceled", "sub", "masterChangeStream$", "pipe", "mergeMap", "ev", "firstValueFrom", "up", "filter", "s", "subscribe", "masterChangeStreamEmit", "unsubscribe", "checkpointQueue", "lastCheckpoint", "promises", "downResult", "masterChangesSince", "pullBatchSize", "documents", "stackCheckpoints", "checkpoint", "persistFromMaster", "Promise", "all", "tasks", "docsOfAllTasks", "forEach", "Error", "appendToArray", "persistenceQueue", "PROMISE_RESOLVE_VOID", "nonPersistedFromMaster", "docs", "primaryPath", "docData", "docId", "downDocsById", "useCheckpoint", "docIds", "Object", "keys", "writeRowsToFork", "writeRowsToForkById", "writeRowsToMeta", "useMetaWriteRows", "forkInstance", "findDocumentsById", "getAssumedMasterState", "currentForkStateList", "assumedMasterState", "currentForkState", "Map", "doc", "set", "map", "forkStateFullDoc", "get", "forkStateDocData", "writeDocToDocState", "hasAttachments", "undefined", "masterState", "assumedMaster", "metaDocument", "isResolvedConflict", "_rev", "isAssumedMasterEqualToForkState", "conflictHandler", "isEqual", "_meta", "getHeightOfRevision", "areStatesExactlyEqual", "getMetaWriteRow", "newForkState", "assign", "flatClone", "_attachments", "getDefaultRevision", "lwt", "now", "nextRevisionHeight", "keepMeta", "forkWriteRow", "previous", "document", "createRevision", "bulkWrite", "downstreamBulkWriteFlag", "forkWriteResult", "success", "getWrittenDocumentsFromBulkWriteResponse", "processed", "mustThrow", "error", "status", "throwMe", "newRxError", "writeError", "metaInstance", "stripAttachmentsDataFromMetaWriteRows", "metaWriteResult", "id", "documentId", "catch", "unhandledError", "resolveConflictError", "state", "input", "forkState", "conflictHandler", "isEqual", "realMasterState", "newDocumentState", "undefined", "resolved", "resolve", "resolvedDoc", "Object", "assign", "_meta", "flatClone", "_rev", "getDefaultRevision", "_attachments", "lwt", "now", "createRevision", "checkpointKey", "assignMethodsToAttachment", "attachment", "Object", "entries", "doc", "collection", "attachments", "forEach", "funName", "fun", "defineProperty", "get", "bind", "fillWriteDataForAttachmentsChange", "primaryPath", "storageInstance", "newDocument", "originalDocument", "_attachments", "Error", "docId", "originalAttachmentsIds", "Set", "keys", "Promise", "all", "map", "key", "value", "has", "ensureNotFalsy", "digest", "data", "attachmentDataString", "getAttachmentData", "RxAttachment", "doc", "id", "type", "length", "digest", "assignMethodsToAttachment", "_proto", "prototype", "remove", "collection", "incrementalWriteQueue", "addWrite", "_data", "docWriteData", "_attachments", "then", "getData", "plainDataBase64", "getDataBase64", "ret", "createBlobFromBase64", "getStringData", "data", "asString", "blobToString", "storageInstance", "getAttachmentData", "primary", "startReplicationUpstream", "state", "input", "initialCheckpoint", "upstream", "checkpointDoc", "getLastCheckpointDoc", "setCheckpoint", "replicationHandler", "streamQueue", "up", "then", "upstreamInitialSync", "processTasks", "timer", "initialSyncStartTime", "openTasks", "persistenceQueue", "PROMISE_RESOLVE_FALSE", "nonPersistedFromMaster", "docs", "sub", "forkInstance", "changeStream", "subscribe", "eventBulk", "events", "paused", "getValue", "stats", "forkChangeStreamEmit", "push", "task", "time", "active", "next", "waitBeforePersist", "subResync", "masterChangeStream$", "pipe", "filter", "ev", "firstValueFrom", "canceled", "unsubscribe", "checkpointQueue", "lastCheckpoint", "promises", "Set", "_loop", "size", "Promise", "race", "Array", "from", "upResult", "getChangedDocumentsSince", "pushBatchSize", "documents", "length", "stackCheckpoints", "checkpoint", "promise", "persistToMaster", "ensureNotFalsy", "add", "catch", "delete", "resolvedPromises", "all", "hadConflicts", "find", "r", "firstSyncDone", "taskWithTime", "shift", "context", "downstreamBulkWriteFlag", "appendToArray", "map", "documentData", "forEach", "docData", "docId", "primaryPath", "upDocsById", "useCheckpoint", "docIds", "Object", "keys", "rememberCheckpointBeforeReturn", "assumedMasterState", "getAssumedMasterState", "writeRowsToMaster", "writeRowsToMasterIds", "writeRowsToMeta", "forkStateById", "fullDocData", "writeDocToDocState", "hasAttachments", "keepMeta", "assumedMasterDoc", "metaDocument", "isResolvedConflict", "_rev", "conflictHandler", "isEqual", "getHeightOfRevision", "_meta", "identifier", "undefined", "newDocumentState", "getMetaWriteRow", "writeRowsArray", "values", "conflictIds", "conflictsById", "writeBatches", "batchArray", "writeBatch", "row", "fillWriteDataForAttachmentsChange", "clone", "masterWriteResult", "masterWrite", "conflictDoc", "id", "useWriteRowsToMeta", "has", "processed", "metaInstance", "bulkWrite", "stripAttachmentsDataFromMetaWriteRows", "hadConflictWrites", "persistToMasterHadConflicts", "conflictWriteFork", "conflictWriteMeta", "entries", "realMasterState", "writeToMasterRow", "resolveConflictError", "resolved", "resolvedConflicts", "output", "previous", "document", "persistToMasterConflictWrites", "forkWriteResult", "mustThrow", "error", "status", "throwMe", "newRxError", "writeError", "useMetaWrites", "success", "getWrittenDocumentsFromBulkWriteResponse", "unhandledError", "replicateRxStorageInstance", "input", "flatClone", "forkInstance", "getUnderlyingPersistentStorage", "metaInstance", "checkpointKeyPromise", "getCheckpointKey", "state", "primaryPath", "getPrimaryFieldOfPrimaryKey", "schema", "primaryKey", "hasAttachments", "attachments", "checkpointKey", "downstreamBulkWriteFlag", "then", "events", "canceled", "BehaviorSubject", "paused", "active", "down", "up", "processed", "Subject", "resolvedConflicts", "error", "stats", "addNewTask", "downstreamProcessChanges", "downstreamResyncOnce", "masterChangeStreamEmit", "persistFromMaster", "forkChangeStreamEmit", "persistToMaster", "persistToMasterConflictWrites", "persistToMasterHadConflicts", "processTasks", "upstreamInitialSync", "firstSyncDone", "streamQueue", "PROMISE_RESOLVE_VOID", "checkpointQueue", "lastCheckpointDoc", "startReplicationDownstream", "startReplicationUpstream", "awaitRxStorageReplicationFirstInSync", "firstValueFrom", "combineLatest", "pipe", "filter", "v", "awaitRxStorageReplicationInSync", "replicationState", "Promise", "all", "awaitRxStorageReplicationIdle", "rxStorageInstanceToReplicationHandler", "instance", "conflictHandler", "databaseInstanceToken", "keepMeta", "replicationHandler", "masterChangeStream$", "changeStream", "mergeMap", "eventBulk", "ret", "checkpoint", "documents", "map", "event", "docData", "writeDocToDocState", "documentData", "fillWriteDataForAttachmentsChange", "clone", "undefined", "masterChangesSince", "batchSize", "getChangedDocumentsSince", "result", "length", "plainDocumentData", "masterWrite", "rows", "rowById", "forEach", "row", "docId", "newDocumentState", "ids", "Object", "keys", "masterDocsStateList", "findDocumentsById", "masterDocsState", "Map", "doc", "set", "conflicts", "writeRows", "entries", "id", "masterState", "get", "push", "document", "docStateToWriteDoc", "assumedMasterState", "isEqual", "ensureNotFalsy", "previous", "bulkWrite", "err", "status", "newRxError", "name", "documentInDb", "cancelRxStorageReplication", "next", "complete", "getIndexMeta", "schema", "index", "fieldNameProperties", "map", "fieldName", "schemaPart", "getSchemaByObjectPath", "Error", "type", "parsedLengths", "getStringLengthOfIndexNumber", "getValue", "objectPathMonad", "maxLength", "getIndexStringPart", "docData", "fieldValue", "padEnd", "getNumberIndexString", "ret", "getIndexableStringMonad", "fieldNamePropertiesAmount", "length", "indexPartsFunctions", "r", "str", "i", "minimum", "Math", "floor", "maximum", "ceil", "multipleOf", "valueSpan", "nonDecimals", "toString", "multipleOfParts", "split", "decimals", "roundedMinimum", "getIndexStringLength", "forEach", "props", "getPrimaryKeyFromIndexableString", "indexableString", "primaryKeyLength", "paddedPrimaryKey", "slice", "primaryKey", "trim", "nonDecimalsValueAsString", "padStart", "splitByDecimalPoint", "decimalValueAsString", "getStartIndexStringFromLowerBound", "lowerBound", "idx", "bound", "ensureNotFalsy", "INDEX_MIN", "INDEX_MAX", "boolToStr", "fillChar", "repeat", "add", "getStartIndexStringFromUpperBound", "upperBound", "changeIndexableStringByOneQuantum", "direction", "lastChar", "charCode", "charCodeAt", "withoutLastChar", "String", "fromCharCode"]
}
